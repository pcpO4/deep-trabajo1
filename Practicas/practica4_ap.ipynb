{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_cell"
      },
      "source": [
        "# Práctica 4: Transfer Learning para MNIST\n",
        "\n",
        "Uso de modelos preentrenados (tf.keras.applications) y comparación con una CNN baseline."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports y configuración\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_pre\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_pre\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_pre\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "np.random.seed(42); tf.random.set_seed(42)\n",
        "print(f'TF: {tf.__version__} | GPU: {tf.config.list_physical_devices(\"GPU\")}')"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga y preprocesado (RGB + resize por backbone)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32')/255.0; x_test = x_test.astype('float32')/255.0\n",
        "x_train_rgb = np.repeat(x_train[..., None], 3, axis=-1)\n",
        "x_test_rgb  = np.repeat(x_test[..., None], 3, axis=-1)\n",
        "y_train_cat = to_categorical(y_train, 10); y_test_cat = to_categorical(y_test, 10)\n",
        "print(x_train_rgb.shape, y_train_cat.shape)"
      ],
      "metadata": {
        "id": "data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generadores de datasets por tamaño y preprocess\n",
        "def make_dataset(x, size, pre_fn):\n",
        "    x_res = tf.image.resize(x, size).numpy()\n",
        "    return pre_fn(x_res)\n",
        "\n",
        "x_vgg_resnet_train = make_dataset(x_train_rgb, (224, 224), vgg_pre)\n",
        "x_vgg_resnet_test  = make_dataset(x_test_rgb,  (224, 224), vgg_pre)\n",
        "x_mnv2_train = make_dataset(x_train_rgb, (96, 96), mobilenet_pre)\n",
        "x_mnv2_test  = make_dataset(x_test_rgb,  (96, 96), mobilenet_pre)\n",
        "x_cnn_train  = tf.image.resize(x_train_rgb, (32, 32)).numpy()\n",
        "x_cnn_test   = tf.image.resize(x_test_rgb,  (32, 32)).numpy()\n",
        "print('Datasets preparados')"
      ],
      "metadata": {
        "id": "prep_variants"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelos\n",
        "def model_vgg16():\n",
        "    base = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3)); base.trainable=False\n",
        "    m = models.Sequential([base, layers.GlobalAveragePooling2D(), layers.Dense(256, activation='relu'), layers.Dropout(0.3), layers.Dense(10, activation='softmax')])\n",
        "    m.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy']); return m\n",
        "\n",
        "def model_resnet50():\n",
        "    base = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3)); base.trainable=False\n",
        "    m = models.Sequential([base, layers.GlobalAveragePooling2D(), layers.Dense(256, activation='relu'), layers.BatchNormalization(), layers.Dropout(0.3), layers.Dense(10, activation='softmax')])\n",
        "    m.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy']); return m\n",
        "\n",
        "def model_mobilenetv2():\n",
        "    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96,96,3)); base.trainable=False\n",
        "    m = models.Sequential([base, layers.GlobalAveragePooling2D(), layers.Dense(128, activation='relu'), layers.Dropout(0.2), layers.Dense(10, activation='softmax')])\n",
        "    m.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy']); return m\n",
        "\n",
        "def model_cnn_baseline():\n",
        "    m = models.Sequential([layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3),padding='same'), layers.MaxPooling2D(), layers.Conv2D(64,(3,3),activation='relu',padding='same'), layers.MaxPooling2D(), layers.Conv2D(128,(3,3),activation='relu',padding='same'), layers.Flatten(), layers.Dense(256,activation='relu'), layers.Dropout(0.5), layers.Dense(10,activation='softmax')])\n",
        "    m.compile(optimizer=Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy']); return m\n",
        "\n",
        "print('Modelos definidos')"
      ],
      "metadata": {
        "id": "models"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "EPOCHS, BATCH_SIZE, VAL_SPLIT = 8, 128, 0.1\n",
        "models_cfg = [\n",
        "    ('VGG16_Transfer', model_vgg16, x_vgg_resnet_train, x_vgg_resnet_test),\n",
        "    ('ResNet50_Transfer', model_resnet50, x_vgg_resnet_train, x_vgg_resnet_test),\n",
        "    ('MobileNetV2_Transfer', model_mobilenetv2, x_mnv2_train, x_mnv2_test),\n",
        "    ('CNN_Baseline', model_cnn_baseline, x_cnn_train, x_cnn_test)\n",
        "]\n",
        "\n",
        "results, histories = {}, {}\n",
        "for name, fn, Xtr, Xte in models_cfg:\n",
        "    print(f'\\nEntrenando {name}...')\n",
        "    m = fn()\n",
        "    h = m.fit(Xtr, y_train_cat, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VAL_SPLIT, verbose=1)\n",
        "    tl, ta = m.evaluate(Xte, y_test_cat, verbose=0)\n",
        "    results[name] = {'model': m, 'test_acc': ta, 'test_loss': tl, 'params': m.count_params()}\n",
        "    histories[name] = h.history\n",
        "    print(f'  Test Acc: {ta:.4f} | Loss: {tl:.4f} | Params: {m.count_params():,}')"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tabla y visualización básica\n",
        "df = pd.DataFrame([{\n",
        "    'Modelo': k, 'Test Acc': f\"{v['test_acc']:.4f}\", 'Test Loss': f\"{v['test_loss']:.4f}\", 'Parámetros': f\"{v['params']:,}\"\n",
        "} for k,v in results.items()]).sort_values('Test Acc', ascending=False)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "for name, h in histories.items():\n",
        "    plt.plot(h['val_accuracy'], label=name)\n",
        "plt.title('Val Accuracy'); plt.xlabel('Época'); plt.ylabel('Accuracy'); plt.legend(); plt.show()"
      ],
      "metadata": {
        "id": "viz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}