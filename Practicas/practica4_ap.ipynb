{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"# **PRÁCTICA 4: TRANSFER LEARNING PARA MNIST**\\n\",\n        \"\\n\",\n        \"## **Enunciado:**\\n\",\n        \"Crear un nuevo modelo usando transfer learning con alguno de los modelos \\n\",\n        \"pre-entrenados vistos en clase como base para clasificar MNIST. \\n\",\n        \"Comparar los resultados con los modelos anteriores.\\n\",\n        \"\\n\",\n        \"**NOTA:** Los modelos pre-entrenados de TensorFlow están en tf.keras.applications\\n\",\n        \"\\n\",\n        \"---\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# ====================================================================\\n\",\n        \"# IMPORTACIONES Y CONFIGURACIÓN\\n\",\n        \"# ====================================================================\\n\",\n        \"\\n\",\n        \"import numpy as np\\n\",\n        \"import tensorflow as tf\\n\",\n        \"from tensorflow import keras\\n\",\n        \"from tensorflow.keras import layers, models\\n\",\n        \"from tensorflow.keras.datasets import mnist\\n\",\n        \"from tensorflow.keras.utils import to_categorical\\n\",\n        \"from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\\n\",\n        \"import matplotlib.pyplot as plt\\n\",\n        \"import time\\n\",\n        \"from sklearn.metrics import classification_report, confusion_matrix\\n\",\n        \"import seaborn as sns\\n\",\n        \"\\n\",\n        \"# Configuración\\n\",\n        \"np.random.seed(42)\\n\",\n        \"tf.random.set_seed(42)\\n\",\n        \"\\n\",\n        \"print(f\\\"TensorFlow versión: {tf.__version__}\\\")\\n\",\n        \"print(f\\\"GPU disponible: {len(tf.config.list_physical_devices('GPU')) > 0}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **1. Preparación de Datos MNIST**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Cargar MNIST\\n\",\n        \"(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n\",\n        \"\\n\",\n        \"# Normalizar [0, 255] -> [0, 1]\\n\",\n        \"x_train = x_train.astype('float32') / 255.0\\n\",\n        \"x_test = x_test.astype('float32') / 255.0\\n\",\n        \"\\n\",\n        \"# Los modelos pre-entrenados esperan 3 canales (RGB)\\n\",\n        \"# MNIST es escala de grises, así que replicamos el canal 3 veces\\n\",\n        \"x_train_rgb = np.stack([x_train] * 3, axis=-1)\\n\",\n        \"x_test_rgb = np.stack([x_test] * 3, axis=-1)\\n\",\n        \"\\n\",\n        \"# Redimensionar de 28x28 a tamaño mínimo requerido (32x32)\\n\",\n        \"x_train_resized = tf.image.resize(x_train_rgb, [32, 32]).numpy()\\n\",\n        \"x_test_resized = tf.image.resize(x_test_rgb, [32, 32]).numpy()\\n\",\n        \"\\n\",\n        \"# One-hot encoding\\n\",\n        \"y_train_cat = to_categorical(y_train, 10)\\n\",\n        \"y_test_cat = to_categorical(y_test, 10)\\n\",\n        \"\\n\",\n        \"print(f\\\"Forma datos entrenamiento: {x_train_resized.shape}\\\")\\n\",\n        \"print(f\\\"Forma datos test: {x_test_resized.shape}\\\")\\n\",\n        \"print(f\\\"Forma labels: {y_train_cat.shape}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **2. Modelo Transfer Learning con VGG16**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"def create_transfer_model_vgg16():\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    Crea modelo con transfer learning usando VGG16 pre-entrenado\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    # Cargar VGG16 pre-entrenado en ImageNet (sin capas superiores)\\n\",\n        \"    base_model = VGG16(\\n\",\n        \"        weights='imagenet',\\n\",\n        \"        include_top=False,\\n\",\n        \"        input_shape=(32, 32, 3)\\n\",\n        \"    )\\n\",\n        \"    \\n\",\n        \"    # Congelar capas del modelo base\\n\",\n        \"    base_model.trainable = False\\n\",\n        \"    \\n\",\n        \"    # Añadir capas personalizadas para MNIST\\n\",\n        \"    model = models.Sequential([\\n\",\n        \"        base_model,\\n\",\n        \"        layers.GlobalAveragePooling2D(),\\n\",\n        \"        layers.Dropout(0.5),\\n\",\n        \"        layers.Dense(128, activation='relu'),\\n\",\n        \"        layers.Dropout(0.3),\\n\",\n        \"        layers.Dense(10, activation='softmax')  # 10 clases MNIST\\n\",\n        \"    ])\\n\",\n        \"    \\n\",\n        \"    return model\\n\",\n        \"\\n\",\n        \"# Crear modelo VGG16\\n\",\n        \"print(\\\"Creando modelo VGG16 con transfer learning...\\\")\\n\",\n        \"vgg16_model = create_transfer_model_vgg16()\\n\",\n        \"\\n\",\n        \"# Compilar\\n\",\n        \"vgg16_model.compile(\\n\",\n        \"    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\\n\",\n        \"    loss='categorical_crossentropy',\\n\",\n        \"    metrics=['accuracy']\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"# Mostrar resumen\\n\",\n        \"print(\\\"\\\\nArquitectura VGG16 Transfer Learning:\\\")\\n\",\n        \"vgg16_model.summary()\\n\",\n        \"\\n\",\n        \"# Información sobre parámetros\\n\",\n        \"total_params = vgg16_model.count_params()\\n\",\n        \"trainable_params = sum([tf.size(w).numpy() for w in vgg16_model.trainable_weights])\\n\",\n        \"non_trainable_params = total_params - trainable_params\\n\",\n        \"\\n\",\n        \"print(f\\\"\\\\nParámetros totales: {total_params:,}\\\")\\n\",\n        \"print(f\\\"Parámetros entrenables: {trainable_params:,}\\\")\\n\",\n        \"print(f\\\"Parámetros congelados: {non_trainable_params:,}\\\")\\n\",\n        \"print(f\\\"Porcentaje congelado: {(non_trainable_params/total_params)*100:.1f}%\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **3. Modelo Transfer Learning con ResNet50**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"def create_transfer_model_resnet50():\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    Crea modelo con transfer learning usando ResNet50 pre-entrenado\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    # Cargar ResNet50 pre-entrenado\\n\",\n        \"    base_model = ResNet50(\\n\",\n        \"        weights='imagenet',\\n\",\n        \"        include_top=False,\\n\",\n        \"        input_shape=(32, 32, 3)\\n\",\n        \"    )\\n\",\n        \"    \\n\",\n        \"    # Congelar capas del modelo base\\n\",\n        \"    base_model.trainable = False\\n\",\n        \"    \\n\",\n        \"    # Añadir capas personalizadas\\n\",\n        \"    model = models.Sequential([\\n\",\n        \"        base_model,\\n\",\n        \"        layers.GlobalAveragePooling2D(),\\n\",\n        \"        layers.Dropout(0.5),\\n\",\n        \"        layers.Dense(256, activation='relu'),\\n\",\n        \"        layers.BatchNormalization(),\\n\",\n        \"        layers.Dropout(0.3),\\n\",\n        \"        layers.Dense(10, activation='softmax')\\n\",\n        \"    ])\\n\",\n        \"    \\n\",\n        \"    return model\\n\",\n        \"\\n\",\n        \"# Crear modelo ResNet50\\n\",\n        \"print(\\\"\\\\nCreando modelo ResNet50 con transfer learning...\\\")\\n\",\n        \"resnet_model = create_transfer_model_resnet50()\\n\",\n        \"\\n\",\n        \"resnet_model.compile(\\n\",\n        \"    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\\n\",\n        \"    loss='categorical_crossentropy',\\n\",\n        \"    metrics=['accuracy']\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"print(f\\\"ResNet50 - Parámetros totales: {resnet_model.count_params():,}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **4. Modelo Transfer Learning con MobileNetV2**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"def create_transfer_model_mobilenet():\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    Crea modelo con transfer learning usando MobileNetV2\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    # MobileNetV2 optimizado para dispositivos móviles\\n\",\n        \"    base_model = MobileNetV2(\\n\",\n        \"        weights='imagenet',\\n\",\n        \"        include_top=False,\\n\",\n        \"        input_shape=(32, 32, 3)\\n\",\n        \"    )\\n\",\n        \"    \\n\",\n        \"    base_model.trainable = False\\n\",\n        \"    \\n\",\n        \"    model = models.Sequential([\\n\",\n        \"        base_model,\\n\",\n        \"        layers.GlobalAveragePooling2D(),\\n\",\n        \"        layers.Dropout(0.4),\\n\",\n        \"        layers.Dense(128, activation='relu'),\\n\",\n        \"        layers.Dropout(0.2),\\n\",\n        \"        layers.Dense(10, activation='softmax')\\n\",\n        \"    ])\\n\",\n        \"    \\n\",\n        \"    return model\\n\",\n        \"\\n\",\n        \"# Crear modelo MobileNetV2\\n\",\n        \"print(\\\"\\\\nCreando modelo MobileNetV2 con transfer learning...\\\")\\n\",\n        \"mobilenet_model = create_transfer_model_mobilenet()\\n\",\n        \"\\n\",\n        \"mobilenet_model.compile(\\n\",\n        \"    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\\n\",\n        \"    loss='categorical_crossentropy',\\n\",\n        \"    metrics=['accuracy']\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"print(f\\\"MobileNetV2 - Parámetros totales: {mobilenet_model.count_params():,}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **5. CNN Simple de Referencia (Para Comparar)**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"def create_simple_cnn():\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    CNN simple entrenada desde cero para comparar con transfer learning\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    model = models.Sequential([\\n\",\n        \"        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\\n\",\n        \"        layers.MaxPooling2D((2, 2)),\\n\",\n        \"        layers.Conv2D(64, (3, 3), activation='relu'),\\n\",\n        \"        layers.MaxPooling2D((2, 2)),\\n\",\n        \"        layers.Conv2D(128, (3, 3), activation='relu'),\\n\",\n        \"        layers.Flatten(),\\n\",\n        \"        layers.Dense(256, activation='relu'),\\n\",\n        \"        layers.Dropout(0.5),\\n\",\n        \"        layers.Dense(10, activation='softmax')\\n\",\n        \"    ])\\n\",\n        \"    \\n\",\n        \"    return model\\n\",\n        \"\\n\",\n        \"# Crear CNN simple\\n\",\n        \"print(\\\"\\\\nCreando CNN simple para comparación...\\\")\\n\",\n        \"simple_cnn = create_simple_cnn()\\n\",\n        \"\\n\",\n        \"simple_cnn.compile(\\n\",\n        \"    optimizer='adam',\\n\",\n        \"    loss='categorical_crossentropy',\\n\",\n        \"    metrics=['accuracy']\\n\",\n        \")\\n\",\n        \"\\n\",\n        \"print(f\\\"CNN Simple - Parámetros totales: {simple_cnn.count_params():,}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **6. Entrenamiento de Todos los Modelos**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Diccionario con todos los modelos\\n\",\n        \"models_dict = {\\n\",\n        \"    'VGG16_Transfer': vgg16_model,\\n\",\n        \"    'ResNet50_Transfer': resnet_model,\\n\",\n        \"    'MobileNetV2_Transfer': mobilenet_model,\\n\",\n        \"    'CNN_Simple': simple_cnn\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"# Configuración de entrenamiento\\n\",\n        \"EPOCHS = 8\\n\",\n        \"BATCH_SIZE = 128\\n\",\n        \"\\n\",\n        \"# Almacenar resultados\\n\",\n        \"results = {}\\n\",\n        \"histories = {}\\n\",\n        \"\\n\",\n        \"print(\\\"\\\" + \\\"=\\\" * 70)\\n\",\n        \"print(\\\"ENTRENAMIENTO COMPARATIVO: TRANSFER LEARNING vs CNN SIMPLE\\\")\\n\",\n        \"print(\\\"=\\\" * 70)\\n\",\n        \"\\n\",\n        \"for name, model in models_dict.items():\\n\",\n        \"    print(f\\\"\\\\n{'='*50}\\\")\\n\",\n        \"    print(f\\\"ENTRENANDO: {name}\\\")\\n\",\n        \"    print(f\\\"{'='*50}\\\")\\n\",\n        \"    \\n\",\n        \"    # Medir tiempo de entrenamiento\\n\",\n        \"    start_time = time.time()\\n\",\n        \"    \\n\",\n        \"    # Entrenar\\n\",\n        \"    history = model.fit(\\n\",\n        \"        x_train_resized, y_train_cat,\\n\",\n        \"        epochs=EPOCHS,\\n\",\n        \"        batch_size=BATCH_SIZE,\\n\",\n        \"        validation_split=0.1,\\n\",\n        \"        verbose=1\\n\",\n        \"    )\\n\",\n        \"    \\n\",\n        \"    training_time = time.time() - start_time\\n\",\n        \"    \\n\",\n        \"    # Evaluar en test\\n\",\n        \"    test_loss, test_accuracy = model.evaluate(x_test_resized, y_test_cat, verbose=0)\\n\",\n        \"    \\n\",\n        \"    # Guardar resultados\\n\",\n        \"    results[name] = {\\n\",\n        \"        'model': model,\\n\",\n        \"        'test_accuracy': test_accuracy,\\n\",\n        \"        'test_loss': test_loss,\\n\",\n        \"        'training_time': training_time,\\n\",\n        \"        'total_params': model.count_params()\\n\",\n        \"    }\\n\",\n        \"    \\n\",\n        \"    histories[name] = history.history\\n\",\n        \"    \\n\",\n        \"    print(f\\\"\\\\n✅ {name} completado:\\\")\\n\",\n        \"    print(f\\\"   📊 Test Accuracy: {test_accuracy*100:.2f}%\\\")\\n\",\n        \"    print(f\\\"   📉 Test Loss: {test_loss:.4f}\\\")\\n\",\n        \"    print(f\\\"   ⏱️  Tiempo: {training_time/60:.2f} minutos\\\")\\n\",\n        \"    print(f\\\"   🔧 Parámetros: {model.count_params():,}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **7. Comparación de Resultados**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Tabla comparativa\\n\",\n        \"print(\\\"\\\\n\\\" + \\\"=\\\" * 80)\\n\",\n        \"print(\\\"TABLA COMPARATIVA: TRANSFER LEARNING vs CNN SIMPLE\\\")\\n\",\n        \"print(\\\"=\\\" * 80)\\n\",\n        \"\\n\",\n        \"print(f\\\"{'Modelo':<20} {'Accuracy':<12} {'Loss':<10} {'Tiempo':<12} {'Parámetros':<15}\\\")\\n\",\n        \"print(\\\"-\\\" * 80)\\n\",\n        \"\\n\",\n        \"for name, result in results.items():\\n\",\n        \"    acc = f\\\"{result['test_accuracy']*100:.2f}%\\\"\\n\",\n        \"    loss = f\\\"{result['test_loss']:.4f}\\\"\\n\",\n        \"    time_min = f\\\"{result['training_time']/60:.2f}min\\\"\\n\",\n        \"    params = f\\\"{result['total_params']:,}\\\"\\n\",\n        \"    \\n\",\n        \"    print(f\\\"{name:<20} {acc:<12} {loss:<10} {time_min:<12} {params:<15}\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"-\\\" * 80)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **8. Visualización de Resultados**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Gráficos comparativos\\n\",\n        \"fig, axes = plt.subplots(2, 2, figsize=(15, 10))\\n\",\n        \"fig.suptitle('Transfer Learning vs CNN Simple - MNIST', fontsize=16, fontweight='bold')\\n\",\n        \"\\n\",\n        \"# Accuracy de entrenamiento\\n\",\n        \"ax = axes[0, 0]\\n\",\n        \"for name, history in histories.items():\\n\",\n        \"    epochs = range(1, len(history['accuracy']) + 1)\\n\",\n        \"    ax.plot(epochs, history['accuracy'], label=name, linewidth=2)\\n\",\n        \"ax.set_title('Training Accuracy')\\n\",\n        \"ax.set_xlabel('Época')\\n\",\n        \"ax.set_ylabel('Accuracy')\\n\",\n        \"ax.legend()\\n\",\n        \"ax.grid(True, alpha=0.3)\\n\",\n        \"\\n\",\n        \"# Accuracy de validación\\n\",\n        \"ax = axes[0, 1]\\n\",\n        \"for name, history in histories.items():\\n\",\n        \"    epochs = range(1, len(history['val_accuracy']) + 1)\\n\",\n        \"    ax.plot(epochs, history['val_accuracy'], label=name, linewidth=2)\\n\",\n        \"ax.set_title('Validation Accuracy')\\n\",\n        \"ax.set_xlabel('Época')\\n\",\n        \"ax.set_ylabel('Accuracy')\\n\",\n        \"ax.legend()\\n\",\n        \"ax.grid(True, alpha=0.3)\\n\",\n        \"\\n\",\n        \"# Loss de entrenamiento\\n\",\n        \"ax = axes[1, 0]\\n\",\n        \"for name, history in histories.items():\\n\",\n        \"    epochs = range(1, len(history['loss']) + 1)\\n\",\n        \"    ax.plot(epochs, history['loss'], label=name, linewidth=2)\\n\",\n        \"ax.set_title('Training Loss')\\n\",\n        \"ax.set_xlabel('Época')\\n\",\n        \"ax.set_ylabel('Loss')\\n\",\n        \"ax.legend()\\n\",\n        \"ax.grid(True, alpha=0.3)\\n\",\n        \"\\n\",\n        \"# Comparación barras\\n\",\n        \"ax = axes[1, 1]\\n\",\n        \"model_names = list(results.keys())\\n\",\n        \"accuracies = [results[name]['test_accuracy']*100 for name in model_names]\\n\",\n        \"\\n\",\n        \"bars = ax.bar(model_names, accuracies, color=['skyblue', 'lightcoral', 'lightgreen', 'orange'], alpha=0.8)\\n\",\n        \"ax.set_title('Test Accuracy Comparison')\\n\",\n        \"ax.set_ylabel('Accuracy (%)')\\n\",\n        \"ax.set_ylim(90, 100)\\n\",\n        \"\\n\",\n        \"# Añadir valores en las barras\\n\",\n        \"for bar, acc in zip(bars, accuracies):\\n\",\n        \"    height = bar.get_height()\\n\",\n        \"    ax.text(bar.get_x() + bar.get_width()/2., height,\\n\",\n        \"            f'{acc:.2f}%', ha='center', va='bottom')\\n\",\n        \"\\n\",\n        \"plt.xticks(rotation=45)\\n\",\n        \"plt.tight_layout()\\n\",\n        \"plt.show()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **9. Análisis Detallado del Mejor Modelo**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Identificar el mejor modelo\\n\",\n        \"best_model_name = max(results.keys(), key=lambda x: results[x]['test_accuracy'])\\n\",\n        \"best_model = results[best_model_name]['model']\\n\",\n        \"best_accuracy = results[best_model_name]['test_accuracy']\\n\",\n        \"\\n\",\n        \"print(f\\\"🏆 MEJOR MODELO: {best_model_name}\\\")\\n\",\n        \"print(f\\\"   Test Accuracy: {best_accuracy*100:.2f}%\\\")\\n\",\n        \"\\n\",\n        \"# Predicciones y matriz de confusión\\n\",\n        \"y_pred = best_model.predict(x_test_resized, verbose=0)\\n\",\n        \"y_pred_classes = np.argmax(y_pred, axis=1)\\n\",\n        \"\\n\",\n        \"# Classification report\\n\",\n        \"print(f\\\"\\\\nClassification Report - {best_model_name}:\\\")\\n\",\n        \"print(classification_report(y_test, y_pred_classes))\\n\",\n        \"\\n\",\n        \"# Matriz de confusión\\n\",\n        \"cm = confusion_matrix(y_test, y_pred_classes)\\n\",\n        \"\\n\",\n        \"plt.figure(figsize=(10, 8))\\n\",\n        \"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \\n\",\n        \"            xticklabels=range(10), yticklabels=range(10))\\n\",\n        \"plt.title(f'Matriz de Confusión - {best_model_name}', fontsize=14, fontweight='bold')\\n\",\n        \"plt.ylabel('Clase Real')\\n\",\n        \"plt.xlabel('Predicción')\\n\",\n        \"plt.show()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **10. Comparación con Modelos Anteriores**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Simular resultados de prácticas anteriores para comparación\\n\",\n        \"previous_results = {\\n\",\n        \"    'Perceptrón (Práctica 0)': 0.925,\\n\",\n        \"    'MLP Optimizado (Práctica 1)': 0.978,\\n\",\n        \"    'MLP Par/Impar (Práctica 2)': 0.995,\\n\",\n        \"    'CNN Simple (Práctica 3)': 0.991\\n\",\n        \"}\\n\",\n        \"\\n\",\n        \"print(\\\"\\\\n\\\" + \\\"=\\\" * 80)\\n\",\n        \"print(\\\"COMPARACIÓN CON MODELOS DE PRÁCTICAS ANTERIORES\\\")\\n\",\n        \"print(\\\"=\\\" * 80)\\n\",\n        \"\\n\",\n        \"# Combinar todos los resultados\\n\",\n        \"all_results = {**previous_results}\\n\",\n        \"for name, result in results.items():\\n\",\n        \"    all_results[f\\\"{name} (Práctica 4)\\\"] = result['test_accuracy']\\n\",\n        \"\\n\",\n        \"# Ordenar por accuracy\\n\",\n        \"sorted_results = sorted(all_results.items(), key=lambda x: x[1], reverse=True)\\n\",\n        \"\\n\",\n        \"print(f\\\"{'Modelo':<35} {'Accuracy':<12}\\\")\\n\",\n        \"print(\\\"-\\\" * 50)\\n\",\n        \"\\n\",\n        \"for i, (model, accuracy) in enumerate(sorted_results):\\n\",\n        \"    print(f\\\"{i+1}. {model:<32} {accuracy*100:.2f}%\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"-\\\" * 50)\\n\",\n        \"\\n\",\n        \"# Análisis\\n\",\n        \"best_overall = sorted_results[0]\\n\",\n        \"print(f\\\"🥇 MEJOR MODELO GLOBAL: {best_overall[0]} ({best_overall[1]*100:.2f}%)\\\")\\n\",\n        \"\\n\",\n        \"# Comparar transfer learning vs CNN simple\\n\",\n        \"transfer_models = [name for name in results.keys() if 'Transfer' in name]\\n\",\n        \"simple_cnn_acc = results['CNN_Simple']['test_accuracy']\\n\",\n        \"\\n\",\n        \"print(f\\\"\\\\n📊 ANÁLISIS TRANSFER LEARNING:\\\")\\n\",\n        \"for model_name in transfer_models:\\n\",\n        \"    acc = results[model_name]['test_accuracy']\\n\",\n        \"    improvement = (acc - simple_cnn_acc) * 100\\n\",\n        \"    if improvement > 0:\\n\",\n        \"        print(f\\\"   ✅ {model_name}: +{improvement:.2f}% vs CNN Simple\\\")\\n\",\n        \"    else:\\n\",\n        \"        print(f\\\"   ❌ {model_name}: {improvement:.2f}% vs CNN Simple\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **11. Conclusiones**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"print(\\\"\\\\n\\\" + \\\"=\\\" * 80)\\n\",\n        \"print(\\\"CONCLUSIONES PRÁCTICA 4 - TRANSFER LEARNING\\\")\\n\",\n        \"print(\\\"=\\\" * 80)\\n\",\n        \"\\n\",\n        \"print(\\\"🎯 OBJETIVOS CUMPLIDOS:\\\")\\n\",\n        \"print(\\\"   ✅ Implementado transfer learning con modelos pre-entrenados\\\")\\n\",\n        \"print(\\\"   ✅ Probados VGG16, ResNet50 y MobileNetV2\\\")\\n\",\n        \"print(\\\"   ✅ Comparados resultados con modelos anteriores\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"📈 HALLAZGOS PRINCIPALES:\\\")\\n\",\n        \"print(\\\"   • Transfer learning utiliza conocimiento de ImageNet\\\")\\n\",\n        \"print(\\\"   • Modelos pre-entrenados tienen millones de parámetros\\\")\\n\",\n        \"print(\\\"   • Solo se entrenan las capas superiores (clasificador)\\\")\\n\",\n        \"print(\\\"   • Tiempo de entrenamiento reducido al congelar capas base\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"⚖️ VENTAJAS DEL TRANSFER LEARNING:\\\")\\n\",\n        \"print(\\\"   ✅ Aprovecha features pre-entrenadas de ImageNet\\\")\\n\",\n        \"print(\\\"   ✅ Menos tiempo de entrenamiento\\\")\\n\",\n        \"print(\\\"   ✅ Buena generalización\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"⚠️ LIMITACIONES:\\\")\\n\",\n        \"print(\\\"   • Modelos diseñados para imágenes RGB naturales\\\")\\n\",\n        \"print(\\\"   • MNIST es muy diferente de ImageNet\\\")\\n\",\n        \"print(\\\"   • Muchos parámetros para un problema simple\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"🔍 RECOMENDACIONES:\\\")\\n\",\n        \"print(\\\"   • Transfer learning es más útil con datasets similares a ImageNet\\\")\\n\",\n        \"print(\\\"   • Para MNIST, una CNN simple puede ser más eficiente\\\")\\n\",\n        \"print(\\\"   • Considerar fine-tuning para mejorar resultados\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"✅ PRÁCTICA 4 COMPLETADA\\\")\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.8.0\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 4\n}