{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "zn_i3mrQH5hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data loading and preprocessing"
      ],
      "metadata": {
        "id": "pEqE8anTH_sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "dataloader = DataLoader(mnist, batch_size=128, shuffle=True)\n"
      ],
      "metadata": {
        "id": "fmyrEuEtH7oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Models definitions"
      ],
      "metadata": {
        "id": "rc8cxTuqIicE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generator"
      ],
      "metadata": {
        "id": "E4D-DDiCIpO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100, img_dim=28*28):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, img_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "3YuooKEmIoB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Discriminator"
      ],
      "metadata": {
        "id": "yEZ_pXCDJBhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_dim=28*28):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(img_dim, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "CRWVu1coI_9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "XGukyn6nKiHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_dim = 100\n",
        "generator = Generator(z_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "lr = 0.0002\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_gen = optim.Adam(generator.parameters(), lr=lr)\n",
        "optimizer_disc = optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "num_epochs = 50  # Change as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for real, _ in dataloader:\n",
        "        real = real.view(-1, 28*28).to(device)\n",
        "        batch_size = real.size(0)\n",
        "\n",
        "        # Labels for real and fake images\n",
        "        label_real = torch.ones(batch_size, 1, device=device)\n",
        "        label_fake = torch.zeros(batch_size, 1, device=device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        noise = torch.randn(batch_size, z_dim, device=device)\n",
        "        fake = generator(noise)\n",
        "        loss_disc_real = criterion(discriminator(real), label_real)\n",
        "        loss_disc_fake = criterion(discriminator(fake.detach()), label_fake)\n",
        "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
        "\n",
        "        optimizer_disc.zero_grad()\n",
        "        loss_disc.backward()\n",
        "        optimizer_disc.step()\n",
        "\n",
        "        # Train Generator\n",
        "        output = discriminator(fake)\n",
        "        loss_gen = criterion(output, label_real)\n",
        "\n",
        "        optimizer_gen.zero_grad()\n",
        "        loss_gen.backward()\n",
        "        optimizer_gen.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}: Loss_D {loss_disc.item()}, Loss_G {loss_gen.item()}\")\n",
        "\n",
        "# Plot losses..."
      ],
      "metadata": {
        "id": "QuqkT3W_J8Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sampling and visualization using the trained generator"
      ],
      "metadata": {
        "id": "_1AUNbtuK1Qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_images=16\n",
        "\n",
        "noise = torch.randn(n_images, z_dim, device=device)\n",
        "gen_imgs = generator(noise).detach().cpu().numpy()\n",
        "gen_imgs = gen_imgs.reshape(n_images, 28, 28)\n",
        "fig, axes = plt.subplots(1, n_images, figsize=(n_images, 1))\n",
        "for img, ax in zip(gen_imgs, axes):\n",
        "    ax.imshow((img + 1) / 2, cmap='gray')\n",
        "    ax.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "f117aiCpKzZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Inception Score (IS) and Fr√®chet Inception Distance (FID)"
      ],
      "metadata": {
        "id": "RgKH9KuxNSgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "MFHOvkKzQG62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.image.inception import InceptionScore\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "\n",
        "gen_images = #...\n",
        "real_images = #...\n",
        "\n",
        "is_metric = InceptionScore()\n",
        "is_score, is_std = is_metric(gen_images)  # generated_images: [N, 3, 299, 299] tensor\n",
        "print('Inception Score:', is_score.item())\n",
        "\n",
        "fid_metric = FrechetInceptionDistance()\n",
        "fid_metric.update(real_images, real=True)\n",
        "fid_metric.update(gen_images, real=False)\n",
        "fid_score = fid_metric.compute()  # Lower is better\n",
        "print('FID:', fid_score.item())\n"
      ],
      "metadata": {
        "id": "NzZSMfLdNYZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torcheval"
      ],
      "metadata": {
        "id": "bpzBkWlidY7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torcheval.metrics import InceptionScore, FrechetInceptionDistance\n",
        "\n",
        "gen_images = #...\n",
        "real_images = #...\n",
        "\n",
        "is_metric = InceptionScore(device=device)\n",
        "is_score, is_std = is_metric(gen_images)  # generated_images: [N, 3, 299, 299] tensor\n",
        "print('Inception Score: ', is_score.item())\n",
        "\n",
        "fid_metric = FrechetInceptionDistance(device=device)\n",
        "fid_metric.update(real_images, real=True)\n",
        "fid_metric.update(gen_images, real=False)\n",
        "fid_score = fid_metric.compute()  # Lower is better\n",
        "print('FID: ', fid_score.item())"
      ],
      "metadata": {
        "id": "nyqUl_s4d2or"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}