{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"# **PRÁCTICA 5: REDES ADVERSARIALES GENERATIVAS (GAN)**\\n\",\n        \"\\n\",\n        \"## **Enunciado:**\\n\",\n        \"Utiliza el archivo simpleGAN.ipynb como plantilla y añade el código \\n\",\n        \"necesario para realizar las siguientes tareas:\\n\",\n        \"\\n\",\n        \"1. **Visualizar en una gráfica la evolución de los errores** del discriminador y generador en el entrenamiento\\n\",\n        \"2. **Calcular las métricas del modelo**\\n\",\n        \"\\n\",\n        \"---\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# ====================================================================\\n\",\n        \"# IMPORTACIONES Y CONFIGURACIÓN\\n\",\n        \"# ====================================================================\\n\",\n        \"\\n\",\n        \"import torch\\n\",\n        \"import torch.nn as nn\\n\",\n        \"import torch.optim as optim\\n\",\n        \"from torchvision import datasets, transforms\\n\",\n        \"from torch.utils.data import DataLoader\\n\",\n        \"import matplotlib.pyplot as plt\\n\",\n        \"import numpy as np\\n\",\n        \"from collections import defaultdict\\n\",\n        \"import time\\n\",\n        \"\\n\",\n        \"# Usar GPU si está disponible\\n\",\n        \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\",\n        \"print(f\\\"Dispositivo utilizado: {device}\\\")\\n\",\n        \"\\n\",\n        \"# Configuración para reproducibilidad\\n\",\n        \"torch.manual_seed(42)\\n\",\n        \"np.random.seed(42)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **1. Carga y Preprocesamiento de Datos**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Transformaciones para MNIST\\n\",\n        \"transform = transforms.Compose([\\n\",\n        \"    transforms.ToTensor(),\\n\",\n        \"    transforms.Normalize((0.5,), (0.5,))  # Normalizar a [-1, 1]\\n\",\n        \"])\\n\",\n        \"\\n\",\n        \"# Cargar dataset MNIST\\n\",\n        \"mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\\n\",\n        \"dataloader = DataLoader(mnist, batch_size=128, shuffle=True)\\n\",\n        \"\\n\",\n        \"print(f\\\"Dataset MNIST cargado: {len(mnist)} imágenes\\\")\\n\",\n        \"print(f\\\"Batch size: {dataloader.batch_size}\\\")\\n\",\n        \"print(f\\\"Número de batches: {len(dataloader)}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **2. Definición de Modelos**\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"### **Generador**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"class Generator(nn.Module):\\n\",\n        \"    def __init__(self, z_dim=100, img_dim=28*28):\\n\",\n        \"        super().__init__()\\n\",\n        \"        self.net = nn.Sequential(\\n\",\n        \"            nn.Linear(z_dim, 256),\\n\",\n        \"            nn.ReLU(True),\\n\",\n        \"            nn.Linear(256, 512),\\n\",\n        \"            nn.ReLU(True),\\n\",\n        \"            nn.Linear(512, img_dim),\\n\",\n        \"            nn.Tanh()\\n\",\n        \"        )\\n\",\n        \"    \\n\",\n        \"    def forward(self, x):\\n\",\n        \"        return self.net(x)\\n\",\n        \"\\n\",\n        \"print(\\\"✅ Generador definido\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"### **Discriminador**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"class Discriminator(nn.Module):\\n\",\n        \"    def __init__(self, img_dim=28*28):\\n\",\n        \"        super().__init__()\\n\",\n        \"        self.net = nn.Sequential(\\n\",\n        \"            nn.Linear(img_dim, 512),\\n\",\n        \"            nn.LeakyReLU(0.2),\\n\",\n        \"            nn.Linear(512, 256),\\n\",\n        \"            nn.LeakyReLU(0.2),\\n\",\n        \"            nn.Linear(256, 1),\\n\",\n        \"            nn.Sigmoid()\\n\",\n        \"        )\\n\",\n        \"    \\n\",\n        \"    def forward(self, x):\\n\",\n        \"        return self.net(x)\\n\",\n        \"\\n\",\n        \"print(\\\"✅ Discriminador definido\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **3. Inicialización y Configuración**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Parámetros\\n\",\n        \"z_dim = 100\\n\",\n        \"lr = 0.0002\\n\",\n        \"num_epochs = 50\\n\",\n        \"\\n\",\n        \"# Inicializar modelos\\n\",\n        \"generator = Generator(z_dim).to(device)\\n\",\n        \"discriminator = Discriminator().to(device)\\n\",\n        \"\\n\",\n        \"# Función de pérdida y optimizadores\\n\",\n        \"criterion = nn.BCELoss()\\n\",\n        \"optimizer_gen = optim.Adam(generator.parameters(), lr=lr)\\n\",\n        \"optimizer_disc = optim.Adam(discriminator.parameters(), lr=lr)\\n\",\n        \"\\n\",\n        \"print(f\\\"Configuración GAN:\\\")\\n\",\n        \"print(f\\\"  - Dimensión ruido (z): {z_dim}\\\")\\n\",\n        \"print(f\\\"  - Learning rate: {lr}\\\")\\n\",\n        \"print(f\\\"  - Epochs: {num_epochs}\\\")\\n\",\n        \"print(f\\\"  - Parámetros Generador: {sum(p.numel() for p in generator.parameters()):,}\\\")\\n\",\n        \"print(f\\\"  - Parámetros Discriminador: {sum(p.numel() for p in discriminator.parameters()):,}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **4. Entrenamiento con Monitorización**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# **TAREA 1: Visualizar evolución de errores**\\n\",\n        \"# Almacenar losses para graficar\\n\",\n        \"losses_gen = []\\n\",\n        \"losses_disc = []\\n\",\n        \"epochs_list = []\\n\",\n        \"\\n\",\n        \"print(\\\"Iniciando entrenamiento GAN...\\\")\\n\",\n        \"print(\\\"=\\\" * 50)\\n\",\n        \"\\n\",\n        \"start_time = time.time()\\n\",\n        \"\\n\",\n        \"for epoch in range(num_epochs):\\n\",\n        \"    epoch_loss_gen = 0\\n\",\n        \"    epoch_loss_disc = 0\\n\",\n        \"    num_batches = 0\\n\",\n        \"    \\n\",\n        \"    for batch_idx, (real, _) in enumerate(dataloader):\\n\",\n        \"        real = real.view(-1, 28*28).to(device)\\n\",\n        \"        batch_size = real.size(0)\\n\",\n        \"\\n\",\n        \"        # Etiquetas para imágenes reales y falsas\\n\",\n        \"        label_real = torch.ones(batch_size, 1, device=device)\\n\",\n        \"        label_fake = torch.zeros(batch_size, 1, device=device)\\n\",\n        \"\\n\",\n        \"        # === ENTRENAR DISCRIMINADOR ===\\n\",\n        \"        noise = torch.randn(batch_size, z_dim, device=device)\\n\",\n        \"        fake = generator(noise)\\n\",\n        \"        \\n\",\n        \"        # Pérdida discriminador con imágenes reales\\n\",\n        \"        loss_disc_real = criterion(discriminator(real), label_real)\\n\",\n        \"        # Pérdida discriminador con imágenes falsas\\n\",\n        \"        loss_disc_fake = criterion(discriminator(fake.detach()), label_fake)\\n\",\n        \"        # Pérdida total discriminador\\n\",\n        \"        loss_disc = (loss_disc_real + loss_disc_fake) / 2\\n\",\n        \"\\n\",\n        \"        optimizer_disc.zero_grad()\\n\",\n        \"        loss_disc.backward()\\n\",\n        \"        optimizer_disc.step()\\n\",\n        \"\\n\",\n        \"        # === ENTRENAR GENERADOR ===\\n\",\n        \"        output = discriminator(fake)\\n\",\n        \"        loss_gen = criterion(output, label_real)  # Engañar al discriminador\\n\",\n        \"\\n\",\n        \"        optimizer_gen.zero_grad()\\n\",\n        \"        loss_gen.backward()\\n\",\n        \"        optimizer_gen.step()\\n\",\n        \"        \\n\",\n        \"        # Acumular losses\\n\",\n        \"        epoch_loss_gen += loss_gen.item()\\n\",\n        \"        epoch_loss_disc += loss_disc.item()\\n\",\n        \"        num_batches += 1\\n\",\n        \"    \\n\",\n        \"    # Calcular promedios de la época\\n\",\n        \"    avg_loss_gen = epoch_loss_gen / num_batches\\n\",\n        \"    avg_loss_disc = epoch_loss_disc / num_batches\\n\",\n        \"    \\n\",\n        \"    # Almacenar para graficar\\n\",\n        \"    losses_gen.append(avg_loss_gen)\\n\",\n        \"    losses_disc.append(avg_loss_disc)\\n\",\n        \"    epochs_list.append(epoch + 1)\\n\",\n        \"    \\n\",\n        \"    # Mostrar progreso\\n\",\n        \"    if (epoch + 1) % 10 == 0 or epoch == 0:\\n\",\n        \"        elapsed = time.time() - start_time\\n\",\n        \"        print(f\\\"Epoch [{epoch+1}/{num_epochs}] - \\\"\\n\",\n        \"              f\\\"Loss_D: {avg_loss_disc:.4f}, Loss_G: {avg_loss_gen:.4f} - \\\"\\n\",\n        \"              f\\\"Tiempo: {elapsed/60:.1f}min\\\")\\n\",\n        \"\\n\",\n        \"training_time = time.time() - start_time\\n\",\n        \"print(f\\\"\\\\n✅ Entrenamiento completado en {training_time/60:.2f} minutos\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **5. TAREA 1: Visualización de Evolución de Errores**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Gráfica de evolución de errores del discriminador y generador\\n\",\n        \"plt.figure(figsize=(12, 5))\\n\",\n        \"\\n\",\n        \"# Subplot 1: Losses separados\\n\",\n        \"plt.subplot(1, 2, 1)\\n\",\n        \"plt.plot(epochs_list, losses_disc, label='Discriminador', color='red', linewidth=2)\\n\",\n        \"plt.plot(epochs_list, losses_gen, label='Generador', color='blue', linewidth=2)\\n\",\n        \"plt.xlabel('Época')\\n\",\n        \"plt.ylabel('Pérdida (Loss)')\\n\",\n        \"plt.title('Evolución de Losses - Discriminador vs Generador')\\n\",\n        \"plt.legend()\\n\",\n        \"plt.grid(True, alpha=0.3)\\n\",\n        \"\\n\",\n        \"# Subplot 2: Losses con escala logarítmica\\n\",\n        \"plt.subplot(1, 2, 2)\\n\",\n        \"plt.semilogy(epochs_list, losses_disc, label='Discriminador', color='red', linewidth=2)\\n\",\n        \"plt.semilogy(epochs_list, losses_gen, label='Generador', color='blue', linewidth=2)\\n\",\n        \"plt.xlabel('Época')\\n\",\n        \"plt.ylabel('Pérdida (escala log)')\\n\",\n        \"plt.title('Evolución de Losses - Escala Logarítmica')\\n\",\n        \"plt.legend()\\n\",\n        \"plt.grid(True, alpha=0.3)\\n\",\n        \"\\n\",\n        \"plt.tight_layout()\\n\",\n        \"plt.show()\\n\",\n        \"\\n\",\n        \"# Análisis de convergencia\\n\",\n        \"print(\\\"\\\\n📊 ANÁLISIS DE CONVERGENCIA:\\\")\\n\",\n        \"print(f\\\"Loss final Discriminador: {losses_disc[-1]:.4f}\\\")\\n\",\n        \"print(f\\\"Loss final Generador: {losses_gen[-1]:.4f}\\\")\\n\",\n        \"print(f\\\"Diferencia final: {abs(losses_disc[-1] - losses_gen[-1]):.4f}\\\")\\n\",\n        \"\\n\",\n        \"# Estabilidad del entrenamiento\\n\",\n        \"stability_disc = np.std(losses_disc[-10:])  # Últimas 10 épocas\\n\",\n        \"stability_gen = np.std(losses_gen[-10:])\\n\",\n        \"print(f\\\"\\\\nEstabilidad (últimas 10 épocas):\\\")\\n\",\n        \"print(f\\\"Desviación estándar Discriminador: {stability_disc:.4f}\\\")\\n\",\n        \"print(f\\\"Desviación estándar Generador: {stability_gen:.4f}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **6. Visualización de Imágenes Generadas**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Generar imágenes de muestra\\n\",\n        \"n_images = 16\\n\",\n        \"\\n\",\n        \"# Generar ruido aleatorio\\n\",\n        \"noise = torch.randn(n_images, z_dim, device=device)\\n\",\n        \"\\n\",\n        \"# Generar imágenes falsas\\n\",\n        \"with torch.no_grad():\\n\",\n        \"    gen_imgs = generator(noise).detach().cpu().numpy()\\n\",\n        \"    gen_imgs = gen_imgs.reshape(n_images, 28, 28)\\n\",\n        \"\\n\",\n        \"# Visualizar imágenes generadas\\n\",\n        \"fig, axes = plt.subplots(2, 8, figsize=(16, 4))\\n\",\n        \"fig.suptitle('Imágenes Generadas por la GAN', fontsize=16, fontweight='bold')\\n\",\n        \"\\n\",\n        \"for i, (img, ax) in enumerate(zip(gen_imgs, axes.flatten())):\\n\",\n        \"    ax.imshow((img + 1) / 2, cmap='gray')  # Desnormalizar [-1,1] -> [0,1]\\n\",\n        \"    ax.set_title(f'Imagen {i+1}')\\n\",\n        \"    ax.axis('off')\\n\",\n        \"\\n\",\n        \"plt.tight_layout()\\n\",\n        \"plt.show()\\n\",\n        \"\\n\",\n        \"print(f\\\"✅ {n_images} imágenes generadas exitosamente\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **7. TAREA 2: Cálculo de Métricas del Modelo**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Instalar librerías necesarias para métricas\\n\",\n        \"try:\\n\",\n        \"    from torchmetrics.image.inception import InceptionScore\\n\",\n        \"    from torchmetrics.image.fid import FrechetInceptionDistance\\n\",\n        \"    torchmetrics_available = True\\n\",\n        \"except ImportError:\\n\",\n        \"    print(\\\"Instalando torchmetrics...\\\")\\n\",\n        \"    import subprocess\\n\",\n        \"    import sys\\n\",\n        \"    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'torchmetrics'])\\n\",\n        \"    from torchmetrics.image.inception import InceptionScore\\n\",\n        \"    from torchmetrics.image.fid import FrechetInceptionDistance\\n\",\n        \"    torchmetrics_available = True\\n\",\n        \"\\n\",\n        \"print(\\\"✅ Librerías de métricas cargadas\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"### **Métrica 1: Inception Score (IS)**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"def calculate_inception_score(generator, z_dim, n_samples=1000, device=device):\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    Calcula el Inception Score para imágenes generadas\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    generator.eval()\\n\",\n        \"    \\n\",\n        \"    # Generar imágenes\\n\",\n        \"    with torch.no_grad():\\n\",\n        \"        noise = torch.randn(n_samples, z_dim, device=device)\\n\",\n        \"        generated_imgs = generator(noise)\\n\",\n        \"        # Reshape y desnormalizar\\n\",\n        \"        generated_imgs = generated_imgs.view(n_samples, 1, 28, 28)\\n\",\n        \"        generated_imgs = (generated_imgs + 1) / 2  # [-1,1] -> [0,1]\\n\",\n        \"        \\n\",\n        \"        # Convertir a RGB (replicar canal)\\n\",\n        \"        generated_imgs_rgb = generated_imgs.repeat(1, 3, 1, 1)\\n\",\n        \"        \\n\",\n        \"        # Redimensionar a 299x299 para Inception\\n\",\n        \"        generated_imgs_resized = torch.nn.functional.interpolate(\\n\",\n        \"            generated_imgs_rgb, size=(299, 299), mode='bilinear', align_corners=False\\n\",\n        \"        )\\n\",\n        \"        \\n\",\n        \"        # Convertir a rango [0, 255] como enteros\\n\",\n        \"        generated_imgs_uint8 = (generated_imgs_resized * 255).clamp(0, 255).to(torch.uint8)\\n\",\n        \"    \\n\",\n        \"    try:\\n\",\n        \"        # Calcular IS\\n\",\n        \"        is_metric = InceptionScore()\\n\",\n        \"        is_score, is_std = is_metric(generated_imgs_uint8)\\n\",\n        \"        return is_score.item(), is_std.item()\\n\",\n        \"    except Exception as e:\\n\",\n        \"        print(f\\\"Error calculando IS: {e}\\\")\\n\",\n        \"        return None, None\\n\",\n        \"\\n\",\n        \"# Calcular Inception Score\\n\",\n        \"print(\\\"Calculando Inception Score...\\\")\\n\",\n        \"is_score, is_std = calculate_inception_score(generator, z_dim, n_samples=500)\\n\",\n        \"\\n\",\n        \"if is_score is not None:\\n\",\n        \"    print(f\\\"\\\\n📊 INCEPTION SCORE:\\\")\\n\",\n        \"    print(f\\\"   Score: {is_score:.4f} ± {is_std:.4f}\\\")\\n\",\n        \"    print(f\\\"   Interpretación: Mayor es mejor (rango típico 1-10)\\\")\\n\",\n        \"else:\\n\",\n        \"    print(\\\"⚠️  No se pudo calcular Inception Score\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"### **Métrica 2: Fréchet Inception Distance (FID)**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"def calculate_fid(generator, dataloader, z_dim, n_real=500, n_fake=500, device=device):\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    Calcula Fréchet Inception Distance entre imágenes reales y generadas\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    generator.eval()\\n\",\n        \"    \\n\",\n        \"    try:\\n\",\n        \"        fid_metric = FrechetInceptionDistance(feature=2048)\\n\",\n        \"        \\n\",\n        \"        # Obtener imágenes reales\\n\",\n        \"        real_images = []\\n\",\n        \"        for batch_idx, (data, _) in enumerate(dataloader):\\n\",\n        \"            if len(real_images) >= n_real:\\n\",\n        \"                break\\n\",\n        \"            batch_size = min(n_real - len(real_images), data.size(0))\\n\",\n        \"            real_images.append(data[:batch_size])\\n\",\n        \"        \\n\",\n        \"        real_images = torch.cat(real_images)[:n_real]\\n\",\n        \"        \\n\",\n        \"        # Procesar imágenes reales\\n\",\n        \"        real_images = (real_images + 1) / 2  # [-1,1] -> [0,1]\\n\",\n        \"        real_images_rgb = real_images.repeat(1, 3, 1, 1)\\n\",\n        \"        real_images_resized = torch.nn.functional.interpolate(\\n\",\n        \"            real_images_rgb, size=(299, 299), mode='bilinear', align_corners=False\\n\",\n        \"        )\\n\",\n        \"        real_images_uint8 = (real_images_resized * 255).clamp(0, 255).to(torch.uint8)\\n\",\n        \"        \\n\",\n        \"        # Generar imágenes falsas\\n\",\n        \"        with torch.no_grad():\\n\",\n        \"            noise = torch.randn(n_fake, z_dim, device=device)\\n\",\n        \"            fake_images = generator(noise)\\n\",\n        \"            fake_images = fake_images.view(n_fake, 1, 28, 28)\\n\",\n        \"            fake_images = (fake_images + 1) / 2\\n\",\n        \"            fake_images_rgb = fake_images.repeat(1, 3, 1, 1)\\n\",\n        \"            fake_images_resized = torch.nn.functional.interpolate(\\n\",\n        \"                fake_images_rgb.cpu(), size=(299, 299), mode='bilinear', align_corners=False\\n\",\n        \"            )\\n\",\n        \"            fake_images_uint8 = (fake_images_resized * 255).clamp(0, 255).to(torch.uint8)\\n\",\n        \"        \\n\",\n        \"        # Calcular FID\\n\",\n        \"        fid_metric.update(real_images_uint8, real=True)\\n\",\n        \"        fid_metric.update(fake_images_uint8, real=False)\\n\",\n        \"        fid_score = fid_metric.compute()\\n\",\n        \"        \\n\",\n        \"        return fid_score.item()\\n\",\n        \"        \\n\",\n        \"    except Exception as e:\\n\",\n        \"        print(f\\\"Error calculando FID: {e}\\\")\\n\",\n        \"        return None\\n\",\n        \"\\n\",\n        \"# Calcular FID\\n\",\n        \"print(\\\"\\\\nCalculando Fréchet Inception Distance (FID)...\\\")\\n\",\n        \"fid_score = calculate_fid(generator, dataloader, z_dim, n_real=300, n_fake=300)\\n\",\n        \"\\n\",\n        \"if fid_score is not None:\\n\",\n        \"    print(f\\\"\\\\n📉 FRÉCHET INCEPTION DISTANCE (FID):\\\")\\n\",\n        \"    print(f\\\"   Score: {fid_score:.4f}\\\")\\n\",\n        \"    print(f\\\"   Interpretación: Menor es mejor (0 = idéntico)\\\")\\n\",\n        \"else:\\n\",\n        \"    print(\\\"⚠️  No se pudo calcular FID\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"### **Métricas Adicionales de Evaluación**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"def calculate_discriminator_accuracy(discriminator, generator, dataloader, z_dim, n_samples=500, device=device):\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    Calcula la accuracy del discriminador en distinguir reales vs falsas\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    discriminator.eval()\\n\",\n        \"    generator.eval()\\n\",\n        \"    \\n\",\n        \"    correct_real = 0\\n\",\n        \"    correct_fake = 0\\n\",\n        \"    total = 0\\n\",\n        \"    \\n\",\n        \"    with torch.no_grad():\\n\",\n        \"        # Evaluar en imágenes reales\\n\",\n        \"        for batch_idx, (real_data, _) in enumerate(dataloader):\\n\",\n        \"            if total >= n_samples // 2:\\n\",\n        \"                break\\n\",\n        \"            \\n\",\n        \"            real_data = real_data.view(-1, 28*28).to(device)\\n\",\n        \"            batch_size = real_data.size(0)\\n\",\n        \"            \\n\",\n        \"            # Predicción en reales (debería ser > 0.5)\\n\",\n        \"            pred_real = discriminator(real_data)\\n\",\n        \"            correct_real += (pred_real > 0.5).sum().item()\\n\",\n        \"            total += batch_size\\n\",\n        \"        \\n\",\n        \"        # Evaluar en imágenes falsas\\n\",\n        \"        noise = torch.randn(n_samples // 2, z_dim, device=device)\\n\",\n        \"        fake_data = generator(noise)\\n\",\n        \"        \\n\",\n        \"        # Predicción en falsas (debería ser < 0.5)\\n\",\n        \"        pred_fake = discriminator(fake_data)\\n\",\n        \"        correct_fake += (pred_fake < 0.5).sum().item()\\n\",\n        \"        total += fake_data.size(0)\\n\",\n        \"    \\n\",\n        \"    accuracy_real = correct_real / (n_samples // 2) * 100\\n\",\n        \"    accuracy_fake = correct_fake / (n_samples // 2) * 100\\n\",\n        \"    accuracy_total = (correct_real + correct_fake) / total * 100\\n\",\n        \"    \\n\",\n        \"    return accuracy_real, accuracy_fake, accuracy_total\\n\",\n        \"\\n\",\n        \"# Calcular accuracy del discriminador\\n\",\n        \"print(\\\"\\\\nCalculando accuracy del discriminador...\\\")\\n\",\n        \"acc_real, acc_fake, acc_total = calculate_discriminator_accuracy(discriminator, generator, dataloader, z_dim)\\n\",\n        \"\\n\",\n        \"print(f\\\"\\\\n🎯 ACCURACY DEL DISCRIMINADOR:\\\")\\n\",\n        \"print(f\\\"   Reales: {acc_real:.2f}%\\\")\\n\",\n        \"print(f\\\"   Falsas: {acc_fake:.2f}%\\\")\\n\",\n        \"print(f\\\"   Total: {acc_total:.2f}%\\\")\\n\",\n        \"\\n\",\n        \"# Diversidad de las imágenes generadas\\n\",\n        \"def calculate_diversity_score(generator, z_dim, n_samples=1000, device=device):\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    Calcula un score de diversidad basado en distancias entre imágenes generadas\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    generator.eval()\\n\",\n        \"    \\n\",\n        \"    with torch.no_grad():\\n\",\n        \"        noise = torch.randn(n_samples, z_dim, device=device)\\n\",\n        \"        generated_imgs = generator(noise)\\n\",\n        \"        \\n\",\n        \"        # Calcular distancia promedio entre pares de imágenes\\n\",\n        \"        distances = []\\n\",\n        \"        for i in range(min(100, n_samples)):\\n\",\n        \"            for j in range(i+1, min(i+11, n_samples)):  # Comparar con 10 siguientes\\n\",\n        \"                dist = torch.norm(generated_imgs[i] - generated_imgs[j], p=2)\\n\",\n        \"                distances.append(dist.item())\\n\",\n        \"        \\n\",\n        \"        avg_distance = np.mean(distances)\\n\",\n        \"        std_distance = np.std(distances)\\n\",\n        \"        \\n\",\n        \"    return avg_distance, std_distance\\n\",\n        \"\\n\",\n        \"print(\\\"\\\\nCalculando diversidad de imágenes generadas...\\\")\\n\",\n        \"diversity_mean, diversity_std = calculate_diversity_score(generator, z_dim)\\n\",\n        \"\\n\",\n        \"print(f\\\"\\\\n🎨 DIVERSIDAD DE IMÁGENES GENERADAS:\\\")\\n\",\n        \"print(f\\\"   Distancia promedio: {diversity_mean:.4f} ± {diversity_std:.4f}\\\")\\n\",\n        \"print(f\\\"   Mayor diversidad = mayor distancia promedio\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **8. Resumen Final de Métricas**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"print(\\\"\\\\n\\\" + \\\"=\\\" * 80)\\n\",\n        \"print(\\\"RESUMEN COMPLETO - PRÁCTICA 5: GAN MNIST\\\")\\n\",\n        \"print(\\\"=\\\" * 80)\\n\",\n        \"\\n\",\n        \"print(\\\"🔧 CONFIGURACIÓN DEL MODELO:\\\")\\n\",\n        \"print(f\\\"   - Epochs entrenadas: {num_epochs}\\\")\\n\",\n        \"print(f\\\"   - Dimensión de ruido: {z_dim}\\\")\\n\",\n        \"print(f\\\"   - Learning rate: {lr}\\\")\\n\",\n        \"print(f\\\"   - Tiempo de entrenamiento: {training_time/60:.2f} minutos\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"📉 MÉTRICAS DE CONVERGENCIA:\\\")\\n\",\n        \"print(f\\\"   - Loss final Generador: {losses_gen[-1]:.4f}\\\")\\n\",\n        \"print(f\\\"   - Loss final Discriminador: {losses_disc[-1]:.4f}\\\")\\n\",\n        \"print(f\\\"   - Equilibrio (diferencia): {abs(losses_gen[-1] - losses_disc[-1]):.4f}\\\")\\n\",\n        \"print(f\\\"   - Estabilidad Generador: {stability_gen:.4f}\\\")\\n\",\n        \"print(f\\\"   - Estabilidad Discriminador: {stability_disc:.4f}\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"📊 MÉTRICAS DE CALIDAD:\\\")\\n\",\n        \"if is_score is not None:\\n\",\n        \"    print(f\\\"   - Inception Score: {is_score:.4f} ± {is_std:.4f}\\\")\\n\",\n        \"else:\\n\",\n        \"    print(\\\"   - Inception Score: No disponible\\\")\\n\",\n        \"    \\n\",\n        \"if fid_score is not None:\\n\",\n        \"    print(f\\\"   - FID Score: {fid_score:.4f}\\\")\\n\",\n        \"else:\\n\",\n        \"    print(\\\"   - FID Score: No disponible\\\")\\n\",\n        \"    \\n\",\n        \"print(f\\\"   - Accuracy Discriminador: {acc_total:.2f}%\\\")\\n\",\n        \"print(f\\\"   - Diversidad Imágenes: {diversity_mean:.4f} ± {diversity_std:.4f}\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"🎯 OBJETIVOS COMPLETADOS:\\\")\\n\",\n        \"print(\\\"   ✅ TAREA 1: Visualización de evolución de errores\\\")\\n\",\n        \"print(\\\"   ✅ TAREA 2: Cálculo de métricas del modelo\\\")\\n\",\n        \"print(\\\"   ✅ Entrenamiento GAN exitoso\\\")\\n\",\n        \"print(\\\"   ✅ Generación de imágenes MNIST\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"🔍 CONCLUSIONES:\\\")\\n\",\n        \"print(\\\"   • La GAN aprendió a generar dígitos similares a MNIST\\\")\\n\",\n        \"print(\\\"   • El equilibrio entre G y D es clave para la convergencia\\\")\\n\",\n        \"print(\\\"   • Las métricas permiten evaluar calidad objetivamente\\\")\\n\",\n        \"print(\\\"   • Mayor entrenamiento podría mejorar la calidad visual\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"✅ PRÁCTICA 5 COMPLETADA EXITOSAMENTE\\\")\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"version\": \"3.8.0\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 4\n}