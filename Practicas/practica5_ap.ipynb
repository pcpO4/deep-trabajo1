{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"# **PR√ÅCTICA 5: REDES ADVERSARIALES GENERATIVAS (GAN)**\\n\",\n        \"\\n\",\n        \"## **Enunciado:**\\n\",\n        \"Utiliza el archivo simpleGAN.ipynb como plantilla y a√±ade el c√≥digo \\n\",\n        \"necesario para realizar las siguientes tareas:\\n\",\n        \"\\n\",\n        \"1. **Visualizar en una gr√°fica la evoluci√≥n de los errores** del discriminador y generador en el entrenamiento\\n\",\n        \"2. **Calcular las m√©tricas del modelo**\\n\",\n        \"\\n\",\n        \"---\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# ====================================================================\\n\",\n        \"# IMPORTACIONES Y CONFIGURACI√ìN\\n\",\n        \"# ====================================================================\\n\",\n        \"\\n\",\n        \"import torch\\n\",\n        \"import torch.nn as nn\\n\",\n        \"import torch.optim as optim\\n\",\n        \"from torchvision import datasets, transforms\\n\",\n        \"from torch.utils.data import DataLoader\\n\",\n        \"import matplotlib.pyplot as plt\\n\",\n        \"import numpy as np\\n\",\n        \"from collections import defaultdict\\n\",\n        \"import time\\n\",\n        \"\\n\",\n        \"# Usar GPU si est√° disponible\\n\",\n        \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\",\n        \"print(f\\\"Dispositivo utilizado: {device}\\\")\\n\",\n        \"\\n\",\n        \"# Configuraci√≥n para reproducibilidad\\n\",\n        \"torch.manual_seed(42)\\n\",\n        \"np.random.seed(42)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **1. Carga y Preprocesamiento de Datos**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Transformaciones para MNIST\\n\",\n        \"transform = transforms.Compose([\\n\",\n        \"    transforms.ToTensor(),\\n\",\n        \"    transforms.Normalize((0.5,), (0.5,))  # Normalizar a [-1, 1]\\n\",\n        \"])\\n\",\n        \"\\n\",\n        \"# Cargar dataset MNIST\\n\",\n        \"mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\\n\",\n        \"dataloader = DataLoader(mnist, batch_size=128, shuffle=True)\\n\",\n        \"\\n\",\n        \"print(f\\\"Dataset MNIST cargado: {len(mnist)} im√°genes\\\")\\n\",\n        \"print(f\\\"Batch size: {dataloader.batch_size}\\\")\\n\",\n        \"print(f\\\"N√∫mero de batches: {len(dataloader)}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **2. Definici√≥n de Modelos**\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"### **Generador**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"class Generator(nn.Module):\\n\",\n        \"    def __init__(self, z_dim=100, img_dim=28*28):\\n\",\n        \"        super().__init__()\\n\",\n        \"        self.net = nn.Sequential(\\n\",\n        \"            nn.Linear(z_dim, 256),\\n\",\n        \"            nn.ReLU(True),\\n\",\n        \"            nn.Linear(256, 512),\\n\",\n        \"            nn.ReLU(True),\\n\",\n        \"            nn.Linear(512, img_dim),\\n\",\n        \"            nn.Tanh()\\n\",\n        \"        )\\n\",\n        \"    \\n\",\n        \"    def forward(self, x):\\n\",\n        \"        return self.net(x)\\n\",\n        \"\\n\",\n        \"print(\\\"‚úÖ Generador definido\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"### **Discriminador**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"class Discriminator(nn.Module):\\n\",\n        \"    def __init__(self, img_dim=28*28):\\n\",\n        \"        super().__init__()\\n\",\n        \"        self.net = nn.Sequential(\\n\",\n        \"            nn.Linear(img_dim, 512),\\n\",\n        \"            nn.LeakyReLU(0.2),\\n\",\n        \"            nn.Linear(512, 256),\\n\",\n        \"            nn.LeakyReLU(0.2),\\n\",\n        \"            nn.Linear(256, 1),\\n\",\n        \"            nn.Sigmoid()\\n\",\n        \"        )\\n\",\n        \"    \\n\",\n        \"    def forward(self, x):\\n\",\n        \"        return self.net(x)\\n\",\n        \"\\n\",\n        \"print(\\\"‚úÖ Discriminador definido\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **3. Inicializaci√≥n y Configuraci√≥n**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Par√°metros\\n\",\n        \"z_dim = 100\\n\",\n        \"lr = 0.0002\\n\",\n        \"num_epochs = 50\\n\",\n        \"\\n\",\n        \"# Inicializar modelos\\n\",\n        \"generator = Generator(z_dim).to(device)\\n\",\n        \"discriminator = Discriminator().to(device)\\n\",\n        \"\\n\",\n        \"# Funci√≥n de p√©rdida y optimizadores\\n\",\n        \"criterion = nn.BCELoss()\\n\",\n        \"optimizer_gen = optim.Adam(generator.parameters(), lr=lr)\\n\",\n        \"optimizer_disc = optim.Adam(discriminator.parameters(), lr=lr)\\n\",\n        \"\\n\",\n        \"print(f\\\"Configuraci√≥n GAN:\\\")\\n\",\n        \"print(f\\\"  - Dimensi√≥n ruido (z): {z_dim}\\\")\\n\",\n        \"print(f\\\"  - Learning rate: {lr}\\\")\\n\",\n        \"print(f\\\"  - Epochs: {num_epochs}\\\")\\n\",\n        \"print(f\\\"  - Par√°metros Generador: {sum(p.numel() for p in generator.parameters()):,}\\\")\\n\",\n        \"print(f\\\"  - Par√°metros Discriminador: {sum(p.numel() for p in discriminator.parameters()):,}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **4. Entrenamiento con Monitorizaci√≥n**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# **TAREA 1: Visualizar evoluci√≥n de errores**\\n\",\n        \"# Almacenar losses para graficar\\n\",\n        \"losses_gen = []\\n\",\n        \"losses_disc = []\\n\",\n        \"epochs_list = []\\n\",\n        \"\\n\",\n        \"print(\\\"Iniciando entrenamiento GAN...\\\")\\n\",\n        \"print(\\\"=\\\" * 50)\\n\",\n        \"\\n\",\n        \"start_time = time.time()\\n\",\n        \"\\n\",\n        \"for epoch in range(num_epochs):\\n\",\n        \"    epoch_loss_gen = 0\\n\",\n        \"    epoch_loss_disc = 0\\n\",\n        \"    num_batches = 0\\n\",\n        \"    \\n\",\n        \"    for batch_idx, (real, _) in enumerate(dataloader):\\n\",\n        \"        real = real.view(-1, 28*28).to(device)\\n\",\n        \"        batch_size = real.size(0)\\n\",\n        \"\\n\",\n        \"        # Etiquetas para im√°genes reales y falsas\\n\",\n        \"        label_real = torch.ones(batch_size, 1, device=device)\\n\",\n        \"        label_fake = torch.zeros(batch_size, 1, device=device)\\n\",\n        \"\\n\",\n        \"        # === ENTRENAR DISCRIMINADOR ===\\n\",\n        \"        noise = torch.randn(batch_size, z_dim, device=device)\\n\",\n        \"        fake = generator(noise)\\n\",\n        \"        \\n\",\n        \"        # P√©rdida discriminador con im√°genes reales\\n\",\n        \"        loss_disc_real = criterion(discriminator(real), label_real)\\n\",\n        \"        # P√©rdida discriminador con im√°genes falsas\\n\",\n        \"        loss_disc_fake = criterion(discriminator(fake.detach()), label_fake)\\n\",\n        \"        # P√©rdida total discriminador\\n\",\n        \"        loss_disc = (loss_disc_real + loss_disc_fake) / 2\\n\",\n        \"\\n\",\n        \"        optimizer_disc.zero_grad()\\n\",\n        \"        loss_disc.backward()\\n\",\n        \"        optimizer_disc.step()\\n\",\n        \"\\n\",\n        \"        # === ENTRENAR GENERADOR ===\\n\",\n        \"        output = discriminator(fake)\\n\",\n        \"        loss_gen = criterion(output, label_real)  # Enga√±ar al discriminador\\n\",\n        \"\\n\",\n        \"        optimizer_gen.zero_grad()\\n\",\n        \"        loss_gen.backward()\\n\",\n        \"        optimizer_gen.step()\\n\",\n        \"        \\n\",\n        \"        # Acumular losses\\n\",\n        \"        epoch_loss_gen += loss_gen.item()\\n\",\n        \"        epoch_loss_disc += loss_disc.item()\\n\",\n        \"        num_batches += 1\\n\",\n        \"    \\n\",\n        \"    # Calcular promedios de la √©poca\\n\",\n        \"    avg_loss_gen = epoch_loss_gen / num_batches\\n\",\n        \"    avg_loss_disc = epoch_loss_disc / num_batches\\n\",\n        \"    \\n\",\n        \"    # Almacenar para graficar\\n\",\n        \"    losses_gen.append(avg_loss_gen)\\n\",\n        \"    losses_disc.append(avg_loss_disc)\\n\",\n        \"    epochs_list.append(epoch + 1)\\n\",\n        \"    \\n\",\n        \"    # Mostrar progreso\\n\",\n        \"    if (epoch + 1) % 10 == 0 or epoch == 0:\\n\",\n        \"        elapsed = time.time() - start_time\\n\",\n        \"        print(f\\\"Epoch [{epoch+1}/{num_epochs}] - \\\"\\n\",\n        \"              f\\\"Loss_D: {avg_loss_disc:.4f}, Loss_G: {avg_loss_gen:.4f} - \\\"\\n\",\n        \"              f\\\"Tiempo: {elapsed/60:.1f}min\\\")\\n\",\n        \"\\n\",\n        \"training_time = time.time() - start_time\\n\",\n        \"print(f\\\"\\\\n‚úÖ Entrenamiento completado en {training_time/60:.2f} minutos\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **5. TAREA 1: Visualizaci√≥n de Evoluci√≥n de Errores**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Gr√°fica de evoluci√≥n de errores del discriminador y generador\\n\",\n        \"plt.figure(figsize=(12, 5))\\n\",\n        \"\\n\",\n        \"# Subplot 1: Losses separados\\n\",\n        \"plt.subplot(1, 2, 1)\\n\",\n        \"plt.plot(epochs_list, losses_disc, label='Discriminador', color='red', linewidth=2)\\n\",\n        \"plt.plot(epochs_list, losses_gen, label='Generador', color='blue', linewidth=2)\\n\",\n        \"plt.xlabel('√âpoca')\\n\",\n        \"plt.ylabel('P√©rdida (Loss)')\\n\",\n        \"plt.title('Evoluci√≥n de Losses - Discriminador vs Generador')\\n\",\n        \"plt.legend()\\n\",\n        \"plt.grid(True, alpha=0.3)\\n\",\n        \"\\n\",\n        \"# Subplot 2: Losses con escala logar√≠tmica\\n\",\n        \"plt.subplot(1, 2, 2)\\n\",\n        \"plt.semilogy(epochs_list, losses_disc, label='Discriminador', color='red', linewidth=2)\\n\",\n        \"plt.semilogy(epochs_list, losses_gen, label='Generador', color='blue', linewidth=2)\\n\",\n        \"plt.xlabel('√âpoca')\\n\",\n        \"plt.ylabel('P√©rdida (escala log)')\\n\",\n        \"plt.title('Evoluci√≥n de Losses - Escala Logar√≠tmica')\\n\",\n        \"plt.legend()\\n\",\n        \"plt.grid(True, alpha=0.3)\\n\",\n        \"\\n\",\n        \"plt.tight_layout()\\n\",\n        \"plt.show()\\n\",\n        \"\\n\",\n        \"# An√°lisis de convergencia\\n\",\n        \"print(\\\"\\\\nüìä AN√ÅLISIS DE CONVERGENCIA:\\\")\\n\",\n        \"print(f\\\"Loss final Discriminador: {losses_disc[-1]:.4f}\\\")\\n\",\n        \"print(f\\\"Loss final Generador: {losses_gen[-1]:.4f}\\\")\\n\",\n        \"print(f\\\"Diferencia final: {abs(losses_disc[-1] - losses_gen[-1]):.4f}\\\")\\n\",\n        \"\\n\",\n        \"# Estabilidad del entrenamiento\\n\",\n        \"stability_disc = np.std(losses_disc[-10:])  # √öltimas 10 √©pocas\\n\",\n        \"stability_gen = np.std(losses_gen[-10:])\\n\",\n        \"print(f\\\"\\\\nEstabilidad (√∫ltimas 10 √©pocas):\\\")\\n\",\n        \"print(f\\\"Desviaci√≥n est√°ndar Discriminador: {stability_disc:.4f}\\\")\\n\",\n        \"print(f\\\"Desviaci√≥n est√°ndar Generador: {stability_gen:.4f}\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **6. Visualizaci√≥n de Im√°genes Generadas**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Generar im√°genes de muestra\\n\",\n        \"n_images = 16\\n\",\n        \"\\n\",\n        \"# Generar ruido aleatorio\\n\",\n        \"noise = torch.randn(n_images, z_dim, device=device)\\n\",\n        \"\\n\",\n        \"# Generar im√°genes falsas\\n\",\n        \"with torch.no_grad():\\n\",\n        \"    gen_imgs = generator(noise).detach().cpu().numpy()\\n\",\n        \"    gen_imgs = gen_imgs.reshape(n_images, 28, 28)\\n\",\n        \"\\n\",\n        \"# Visualizar im√°genes generadas\\n\",\n        \"fig, axes = plt.subplots(2, 8, figsize=(16, 4))\\n\",\n        \"fig.suptitle('Im√°genes Generadas por la GAN', fontsize=16, fontweight='bold')\\n\",\n        \"\\n\",\n        \"for i, (img, ax) in enumerate(zip(gen_imgs, axes.flatten())):\\n\",\n        \"    ax.imshow((img + 1) / 2, cmap='gray')  # Desnormalizar [-1,1] -> [0,1]\\n\",\n        \"    ax.set_title(f'Imagen {i+1}')\\n\",\n        \"    ax.axis('off')\\n\",\n        \"\\n\",\n        \"plt.tight_layout()\\n\",\n        \"plt.show()\\n\",\n        \"\\n\",\n        \"print(f\\\"‚úÖ {n_images} im√°genes generadas exitosamente\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **7. TAREA 2: C√°lculo de M√©tricas del Modelo**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"# Instalar librer√≠as necesarias para m√©tricas\\n\",\n        \"try:\\n\",\n        \"    from torchmetrics.image.inception import InceptionScore\\n\",\n        \"    from torchmetrics.image.fid import FrechetInceptionDistance\\n\",\n        \"    torchmetrics_available = True\\n\",\n        \"except ImportError:\\n\",\n        \"    print(\\\"Instalando torchmetrics...\\\")\\n\",\n        \"    import subprocess\\n\",\n        \"    import sys\\n\",\n        \"    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'torchmetrics'])\\n\",\n        \"    from torchmetrics.image.inception import InceptionScore\\n\",\n        \"    from torchmetrics.image.fid import FrechetInceptionDistance\\n\",\n        \"    torchmetrics_available = True\\n\",\n        \"\\n\",\n        \"print(\\\"‚úÖ Librer√≠as de m√©tricas cargadas\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"### **M√©trica 1: Inception Score (IS)**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"def calculate_inception_score(generator, z_dim, n_samples=1000, device=device):\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    Calcula el Inception Score para im√°genes generadas\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    generator.eval()\\n\",\n        \"    \\n\",\n        \"    # Generar im√°genes\\n\",\n        \"    with torch.no_grad():\\n\",\n        \"        noise = torch.randn(n_samples, z_dim, device=device)\\n\",\n        \"        generated_imgs = generator(noise)\\n\",\n        \"        # Reshape y desnormalizar\\n\",\n        \"        generated_imgs = generated_imgs.view(n_samples, 1, 28, 28)\\n\",\n        \"        generated_imgs = (generated_imgs + 1) / 2  # [-1,1] -> [0,1]\\n\",\n        \"        \\n\",\n        \"        # Convertir a RGB (replicar canal)\\n\",\n        \"        generated_imgs_rgb = generated_imgs.repeat(1, 3, 1, 1)\\n\",\n        \"        \\n\",\n        \"        # Redimensionar a 299x299 para Inception\\n\",\n        \"        generated_imgs_resized = torch.nn.functional.interpolate(\\n\",\n        \"            generated_imgs_rgb, size=(299, 299), mode='bilinear', align_corners=False\\n\",\n        \"        )\\n\",\n        \"        \\n\",\n        \"        # Convertir a rango [0, 255] como enteros\\n\",\n        \"        generated_imgs_uint8 = (generated_imgs_resized * 255).clamp(0, 255).to(torch.uint8)\\n\",\n        \"    \\n\",\n        \"    try:\\n\",\n        \"        # Calcular IS\\n\",\n        \"        is_metric = InceptionScore()\\n\",\n        \"        is_score, is_std = is_metric(generated_imgs_uint8)\\n\",\n        \"        return is_score.item(), is_std.item()\\n\",\n        \"    except Exception as e:\\n\",\n        \"        print(f\\\"Error calculando IS: {e}\\\")\\n\",\n        \"        return None, None\\n\",\n        \"\\n\",\n        \"# Calcular Inception Score\\n\",\n        \"print(\\\"Calculando Inception Score...\\\")\\n\",\n        \"is_score, is_std = calculate_inception_score(generator, z_dim, n_samples=500)\\n\",\n        \"\\n\",\n        \"if is_score is not None:\\n\",\n        \"    print(f\\\"\\\\nüìä INCEPTION SCORE:\\\")\\n\",\n        \"    print(f\\\"   Score: {is_score:.4f} ¬± {is_std:.4f}\\\")\\n\",\n        \"    print(f\\\"   Interpretaci√≥n: Mayor es mejor (rango t√≠pico 1-10)\\\")\\n\",\n        \"else:\\n\",\n        \"    print(\\\"‚ö†Ô∏è  No se pudo calcular Inception Score\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"### **M√©trica 2: Fr√©chet Inception Distance (FID)**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"def calculate_fid(generator, dataloader, z_dim, n_real=500, n_fake=500, device=device):\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    Calcula Fr√©chet Inception Distance entre im√°genes reales y generadas\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    generator.eval()\\n\",\n        \"    \\n\",\n        \"    try:\\n\",\n        \"        fid_metric = FrechetInceptionDistance(feature=2048)\\n\",\n        \"        \\n\",\n        \"        # Obtener im√°genes reales\\n\",\n        \"        real_images = []\\n\",\n        \"        for batch_idx, (data, _) in enumerate(dataloader):\\n\",\n        \"            if len(real_images) >= n_real:\\n\",\n        \"                break\\n\",\n        \"            batch_size = min(n_real - len(real_images), data.size(0))\\n\",\n        \"            real_images.append(data[:batch_size])\\n\",\n        \"        \\n\",\n        \"        real_images = torch.cat(real_images)[:n_real]\\n\",\n        \"        \\n\",\n        \"        # Procesar im√°genes reales\\n\",\n        \"        real_images = (real_images + 1) / 2  # [-1,1] -> [0,1]\\n\",\n        \"        real_images_rgb = real_images.repeat(1, 3, 1, 1)\\n\",\n        \"        real_images_resized = torch.nn.functional.interpolate(\\n\",\n        \"            real_images_rgb, size=(299, 299), mode='bilinear', align_corners=False\\n\",\n        \"        )\\n\",\n        \"        real_images_uint8 = (real_images_resized * 255).clamp(0, 255).to(torch.uint8)\\n\",\n        \"        \\n\",\n        \"        # Generar im√°genes falsas\\n\",\n        \"        with torch.no_grad():\\n\",\n        \"            noise = torch.randn(n_fake, z_dim, device=device)\\n\",\n        \"            fake_images = generator(noise)\\n\",\n        \"            fake_images = fake_images.view(n_fake, 1, 28, 28)\\n\",\n        \"            fake_images = (fake_images + 1) / 2\\n\",\n        \"            fake_images_rgb = fake_images.repeat(1, 3, 1, 1)\\n\",\n        \"            fake_images_resized = torch.nn.functional.interpolate(\\n\",\n        \"                fake_images_rgb.cpu(), size=(299, 299), mode='bilinear', align_corners=False\\n\",\n        \"            )\\n\",\n        \"            fake_images_uint8 = (fake_images_resized * 255).clamp(0, 255).to(torch.uint8)\\n\",\n        \"        \\n\",\n        \"        # Calcular FID\\n\",\n        \"        fid_metric.update(real_images_uint8, real=True)\\n\",\n        \"        fid_metric.update(fake_images_uint8, real=False)\\n\",\n        \"        fid_score = fid_metric.compute()\\n\",\n        \"        \\n\",\n        \"        return fid_score.item()\\n\",\n        \"        \\n\",\n        \"    except Exception as e:\\n\",\n        \"        print(f\\\"Error calculando FID: {e}\\\")\\n\",\n        \"        return None\\n\",\n        \"\\n\",\n        \"# Calcular FID\\n\",\n        \"print(\\\"\\\\nCalculando Fr√©chet Inception Distance (FID)...\\\")\\n\",\n        \"fid_score = calculate_fid(generator, dataloader, z_dim, n_real=300, n_fake=300)\\n\",\n        \"\\n\",\n        \"if fid_score is not None:\\n\",\n        \"    print(f\\\"\\\\nüìâ FR√âCHET INCEPTION DISTANCE (FID):\\\")\\n\",\n        \"    print(f\\\"   Score: {fid_score:.4f}\\\")\\n\",\n        \"    print(f\\\"   Interpretaci√≥n: Menor es mejor (0 = id√©ntico)\\\")\\n\",\n        \"else:\\n\",\n        \"    print(\\\"‚ö†Ô∏è  No se pudo calcular FID\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"### **M√©tricas Adicionales de Evaluaci√≥n**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"def calculate_discriminator_accuracy(discriminator, generator, dataloader, z_dim, n_samples=500, device=device):\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    Calcula la accuracy del discriminador en distinguir reales vs falsas\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    discriminator.eval()\\n\",\n        \"    generator.eval()\\n\",\n        \"    \\n\",\n        \"    correct_real = 0\\n\",\n        \"    correct_fake = 0\\n\",\n        \"    total = 0\\n\",\n        \"    \\n\",\n        \"    with torch.no_grad():\\n\",\n        \"        # Evaluar en im√°genes reales\\n\",\n        \"        for batch_idx, (real_data, _) in enumerate(dataloader):\\n\",\n        \"            if total >= n_samples // 2:\\n\",\n        \"                break\\n\",\n        \"            \\n\",\n        \"            real_data = real_data.view(-1, 28*28).to(device)\\n\",\n        \"            batch_size = real_data.size(0)\\n\",\n        \"            \\n\",\n        \"            # Predicci√≥n en reales (deber√≠a ser > 0.5)\\n\",\n        \"            pred_real = discriminator(real_data)\\n\",\n        \"            correct_real += (pred_real > 0.5).sum().item()\\n\",\n        \"            total += batch_size\\n\",\n        \"        \\n\",\n        \"        # Evaluar en im√°genes falsas\\n\",\n        \"        noise = torch.randn(n_samples // 2, z_dim, device=device)\\n\",\n        \"        fake_data = generator(noise)\\n\",\n        \"        \\n\",\n        \"        # Predicci√≥n en falsas (deber√≠a ser < 0.5)\\n\",\n        \"        pred_fake = discriminator(fake_data)\\n\",\n        \"        correct_fake += (pred_fake < 0.5).sum().item()\\n\",\n        \"        total += fake_data.size(0)\\n\",\n        \"    \\n\",\n        \"    accuracy_real = correct_real / (n_samples // 2) * 100\\n\",\n        \"    accuracy_fake = correct_fake / (n_samples // 2) * 100\\n\",\n        \"    accuracy_total = (correct_real + correct_fake) / total * 100\\n\",\n        \"    \\n\",\n        \"    return accuracy_real, accuracy_fake, accuracy_total\\n\",\n        \"\\n\",\n        \"# Calcular accuracy del discriminador\\n\",\n        \"print(\\\"\\\\nCalculando accuracy del discriminador...\\\")\\n\",\n        \"acc_real, acc_fake, acc_total = calculate_discriminator_accuracy(discriminator, generator, dataloader, z_dim)\\n\",\n        \"\\n\",\n        \"print(f\\\"\\\\nüéØ ACCURACY DEL DISCRIMINADOR:\\\")\\n\",\n        \"print(f\\\"   Reales: {acc_real:.2f}%\\\")\\n\",\n        \"print(f\\\"   Falsas: {acc_fake:.2f}%\\\")\\n\",\n        \"print(f\\\"   Total: {acc_total:.2f}%\\\")\\n\",\n        \"\\n\",\n        \"# Diversidad de las im√°genes generadas\\n\",\n        \"def calculate_diversity_score(generator, z_dim, n_samples=1000, device=device):\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    Calcula un score de diversidad basado en distancias entre im√°genes generadas\\n\",\n        \"    \\\"\\\"\\\"\\n\",\n        \"    generator.eval()\\n\",\n        \"    \\n\",\n        \"    with torch.no_grad():\\n\",\n        \"        noise = torch.randn(n_samples, z_dim, device=device)\\n\",\n        \"        generated_imgs = generator(noise)\\n\",\n        \"        \\n\",\n        \"        # Calcular distancia promedio entre pares de im√°genes\\n\",\n        \"        distances = []\\n\",\n        \"        for i in range(min(100, n_samples)):\\n\",\n        \"            for j in range(i+1, min(i+11, n_samples)):  # Comparar con 10 siguientes\\n\",\n        \"                dist = torch.norm(generated_imgs[i] - generated_imgs[j], p=2)\\n\",\n        \"                distances.append(dist.item())\\n\",\n        \"        \\n\",\n        \"        avg_distance = np.mean(distances)\\n\",\n        \"        std_distance = np.std(distances)\\n\",\n        \"        \\n\",\n        \"    return avg_distance, std_distance\\n\",\n        \"\\n\",\n        \"print(\\\"\\\\nCalculando diversidad de im√°genes generadas...\\\")\\n\",\n        \"diversity_mean, diversity_std = calculate_diversity_score(generator, z_dim)\\n\",\n        \"\\n\",\n        \"print(f\\\"\\\\nüé® DIVERSIDAD DE IM√ÅGENES GENERADAS:\\\")\\n\",\n        \"print(f\\\"   Distancia promedio: {diversity_mean:.4f} ¬± {diversity_std:.4f}\\\")\\n\",\n        \"print(f\\\"   Mayor diversidad = mayor distancia promedio\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"## **8. Resumen Final de M√©tricas**\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [],\n      \"source\": [\n        \"print(\\\"\\\\n\\\" + \\\"=\\\" * 80)\\n\",\n        \"print(\\\"RESUMEN COMPLETO - PR√ÅCTICA 5: GAN MNIST\\\")\\n\",\n        \"print(\\\"=\\\" * 80)\\n\",\n        \"\\n\",\n        \"print(\\\"üîß CONFIGURACI√ìN DEL MODELO:\\\")\\n\",\n        \"print(f\\\"   - Epochs entrenadas: {num_epochs}\\\")\\n\",\n        \"print(f\\\"   - Dimensi√≥n de ruido: {z_dim}\\\")\\n\",\n        \"print(f\\\"   - Learning rate: {lr}\\\")\\n\",\n        \"print(f\\\"   - Tiempo de entrenamiento: {training_time/60:.2f} minutos\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"üìâ M√âTRICAS DE CONVERGENCIA:\\\")\\n\",\n        \"print(f\\\"   - Loss final Generador: {losses_gen[-1]:.4f}\\\")\\n\",\n        \"print(f\\\"   - Loss final Discriminador: {losses_disc[-1]:.4f}\\\")\\n\",\n        \"print(f\\\"   - Equilibrio (diferencia): {abs(losses_gen[-1] - losses_disc[-1]):.4f}\\\")\\n\",\n        \"print(f\\\"   - Estabilidad Generador: {stability_gen:.4f}\\\")\\n\",\n        \"print(f\\\"   - Estabilidad Discriminador: {stability_disc:.4f}\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"üìä M√âTRICAS DE CALIDAD:\\\")\\n\",\n        \"if is_score is not None:\\n\",\n        \"    print(f\\\"   - Inception Score: {is_score:.4f} ¬± {is_std:.4f}\\\")\\n\",\n        \"else:\\n\",\n        \"    print(\\\"   - Inception Score: No disponible\\\")\\n\",\n        \"    \\n\",\n        \"if fid_score is not None:\\n\",\n        \"    print(f\\\"   - FID Score: {fid_score:.4f}\\\")\\n\",\n        \"else:\\n\",\n        \"    print(\\\"   - FID Score: No disponible\\\")\\n\",\n        \"    \\n\",\n        \"print(f\\\"   - Accuracy Discriminador: {acc_total:.2f}%\\\")\\n\",\n        \"print(f\\\"   - Diversidad Im√°genes: {diversity_mean:.4f} ¬± {diversity_std:.4f}\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"üéØ OBJETIVOS COMPLETADOS:\\\")\\n\",\n        \"print(\\\"   ‚úÖ TAREA 1: Visualizaci√≥n de evoluci√≥n de errores\\\")\\n\",\n        \"print(\\\"   ‚úÖ TAREA 2: C√°lculo de m√©tricas del modelo\\\")\\n\",\n        \"print(\\\"   ‚úÖ Entrenamiento GAN exitoso\\\")\\n\",\n        \"print(\\\"   ‚úÖ Generaci√≥n de im√°genes MNIST\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"üîç CONCLUSIONES:\\\")\\n\",\n        \"print(\\\"   ‚Ä¢ La GAN aprendi√≥ a generar d√≠gitos similares a MNIST\\\")\\n\",\n        \"print(\\\"   ‚Ä¢ El equilibrio entre G y D es clave para la convergencia\\\")\\n\",\n        \"print(\\\"   ‚Ä¢ Las m√©tricas permiten evaluar calidad objetivamente\\\")\\n\",\n        \"print(\\\"   ‚Ä¢ Mayor entrenamiento podr√≠a mejorar la calidad visual\\\")\\n\",\n        \"\\n\",\n        \"print(\\\"‚úÖ PR√ÅCTICA 5 COMPLETADA EXITOSAMENTE\\\")\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"version\": \"3.8.0\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 4\n}