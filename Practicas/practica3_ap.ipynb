{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **PR√ÅCTICA 3: RED NEURONAL CONVOLUCIONAL (CNN) PARA MNIST**\n",
        "\n",
        "## **Objetivos de la pr√°ctica:**\n",
        "- Crear una red convolucional simple (CNN) para clasificar MNIST\n",
        "- Probar distintas arquitecturas combinando capas vistas en clase\n",
        "- Comparar rendimiento y resultados de diferentes CNNs propuestas\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# IMPORTACI√ìN DE LIBRER√çAS\n",
        "# ====================================================================\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import time\n",
        "\n",
        "# Configuraci√≥n para reproducibilidad\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Configurar matplotlib\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "print(f\"TensorFlow versi√≥n: {tf.__version__}\")\n",
        "print(f\"GPU disponible: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **1. Carga y Preprocesamiento de Datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalizaci√≥n [0, 255] -> [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape para CNNs: (samples, height, width, channels)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# One-hot encoding de labels\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "print(f\"X_train shape: {x_train.shape}\")\n",
        "print(f\"Y_train shape: {y_train_cat.shape}\")\n",
        "print(f\"X_test shape: {x_test.shape}\")\n",
        "print(f\"Y_test shape: {y_test_cat.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizaci√≥n de algunas im√°genes\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "fig.suptitle('Muestra del dataset MNIST', fontsize=14, fontweight='bold')\n",
        "\n",
        "for i in range(10):\n",
        "    ax = axes[i//5, i%5]\n",
        "    ax.imshow(x_train[i].reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(f'Clase: {y_train[i]}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **2. Dise√±o de Arquitecturas CNN**\n",
        "\n",
        "Probaremos diferentes arquitecturas para comparar su rendimiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# CNN B√ÅSICA (Baseline)\n",
        "# ====================================================================\n",
        "\n",
        "def create_basic_cnn():\n",
        "    \"\"\"\n",
        "    CNN b√°sica con 2 capas convolucionales.\n",
        "    Arquitectura simple para baseline.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', \n",
        "                      input_shape=(28, 28, 1), padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ], name='CNN_Basic')\n",
        "    \n",
        "    return model\n",
        "\n",
        "# ====================================================================\n",
        "# CNN INTERMEDIA (M√°s profunda)\n",
        "# ====================================================================\n",
        "\n",
        "def create_intermediate_cnn():\n",
        "    \"\"\"\n",
        "    CNN intermedia con 3 capas convolucionales.\n",
        "    Incluye Dropout para regularizaci√≥n.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', \n",
        "                      input_shape=(28, 28, 1), padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ], name='CNN_Intermediate')\n",
        "    \n",
        "    return model\n",
        "\n",
        "# ====================================================================\n",
        "# CNN AVANZADA (Con Batch Normalization)\n",
        "# ====================================================================\n",
        "\n",
        "def create_advanced_cnn():\n",
        "    \"\"\"\n",
        "    CNN avanzada con m√°s capas y Batch Normalization.\n",
        "    Arquitectura m√°s compleja y robusta.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', \n",
        "                      input_shape=(28, 28, 1), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ], name='CNN_Advanced')\n",
        "    \n",
        "    return model\n",
        "\n",
        "# ====================================================================\n",
        "# CNN COMPACTA (Menos par√°metros, m√°s eficiente)\n",
        "# ====================================================================\n",
        "\n",
        "def create_compact_cnn():\n",
        "    \"\"\"\n",
        "    CNN compacta con menos par√°metros pero bien optimizada.\n",
        "    Incluye separable convolutions para eficiencia.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (5, 5), activation='relu', \n",
        "                      input_shape=(28, 28, 1), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        layers.SeparableConv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        layers.SeparableConv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        \n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ], name='CNN_Compact')\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **3. Entrenamiento de Modelos CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lista de modelos CNN a entrenar\n",
        "cnn_models = {\n",
        "    'CNN_Basic': create_basic_cnn(),\n",
        "    'CNN_Intermediate': create_intermediate_cnn(),\n",
        "    'CNN_Advanced': create_advanced_cnn(),\n",
        "    'CNN_Compact': create_compact_cnn()\n",
        "}\n",
        "\n",
        "# Diccionario para guardar historias de entrenamiento\n",
        "histories = {}\n",
        "\n",
        "# Configuraci√≥n de entrenamiento\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ENTRENAMIENTO DE REDES NEURONALES CONVOLUCIONALES\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar cada modelo\n",
        "for name, model in cnn_models.items():\n",
        "    print(f\"\\n{'-'*80}\")\n",
        "    print(f\"ENTRENANDO: {name}\")\n",
        "    print(f\"{'-'*80}\")\n",
        "    \n",
        "    # Compilar el modelo\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    # Mostrar resumen del modelo\n",
        "    print(f\"\\nArquitectura de {name}:\")\n",
        "    model.summary()\n",
        "    \n",
        "    # Callbacks para mejores resultados\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
        "    ]\n",
        "    \n",
        "    # Medir tiempo de entrenamiento\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Entrenar el modelo\n",
        "    history = model.fit(\n",
        "        x_train, y_train_cat,\n",
        "        validation_split=0.1,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"\\n‚è±Ô∏è  Tiempo de entrenamiento: {training_time/60:.2f} minutos\")\n",
        "    \n",
        "    # Guardar historia\n",
        "    histories[name] = history.history\n",
        "    \n",
        "    # Evaluar en conjunto de test\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test_cat, verbose=0)\n",
        "    \n",
        "    print(f\"\\nüìä RESULTADOS FINALES para {name}:\")\n",
        "    print(f\"   Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "    print(f\"   Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"   Par√°metros totales: {model.count_params():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **4. An√°lisis y Comparaci√≥n de Resultados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizaci√≥n de las curvas de entrenamiento\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Comparaci√≥n de Arquitecturas CNN', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Training Accuracy\n",
        "ax = axes[0, 0]\n",
        "for name, history in histories.items():\n",
        "    ax.plot(history['accuracy'], label=name)\n",
        "ax.set_title('Accuracy de Entrenamiento')\n",
        "ax.set_xlabel('√âpoca')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Training Loss\n",
        "ax = axes[0, 1]\n",
        "for name, history in histories.items():\n",
        "    ax.plot(history['loss'], label=name)\n",
        "ax.set_title('Loss de Entrenamiento')\n",
        "ax.set_xlabel('√âpoca')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Validation Accuracy\n",
        "ax = axes[1, 0]\n",
        "for name, history in histories.items():\n",
        "    ax.plot(history['val_accuracy'], label=name)\n",
        "ax.set_title('Accuracy de Validaci√≥n')\n",
        "ax.set_xlabel('√âpoca')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Validation Loss\n",
        "ax = axes[1, 1]\n",
        "for name, history in histories.items():\n",
        "    ax.plot(history['val_loss'], label=name)\n",
        "ax.set_title('Loss de Validaci√≥n')\n",
        "ax.set_xlabel('√âpoca')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tabla comparativa de resultados\n",
        "comparison_data = []\n",
        "\n",
        "for name, model in cnn_models.items():\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test_cat, verbose=0)\n",
        "    total_params = model.count_params()\n",
        "    \n",
        "    comparison_data.append({\n",
        "        'Modelo': name,\n",
        "        'Test Accuracy': f\"{test_acc:.4f}\",\n",
        "        'Test Loss': f\"{test_loss:.4f}\",\n",
        "        'Par√°metros': f\"{total_params:,}\",\n",
        "        'Accuracy %': f\"{test_acc*100:.2f}%\"\n",
        "    })\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "print(\"TABLA COMPARATIVA - REDES NEURONALES CONVOLUCIONALES\")\n",
        "print(\"=\" * 100)\n",
        "print(f\"{' ' * 5}Modelo{' ' * 10}Test Accuracy{' ' * 5}Test Loss{' ' * 5}Par√°metros{' ' * 5}Accuracy %\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for data in comparison_data:\n",
        "    print(f\"{data['Modelo']:15} {data['Test Accuracy']:>12} {data['Test Loss']:>12} {data['Par√°metros']:>12} {data['Accuracy %']:>12}\")\n",
        "\n",
        "print(\"-\" * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **5. An√°lisis Detallado del Mejor Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seleccionar el mejor modelo basado en test accuracy\n",
        "test_accs = {name: model.evaluate(x_test, y_test_cat, verbose=0)[1] for name, model in cnn_models.items()}\n",
        "best_model_name = max(test_accs, key=test_accs.get)\n",
        "best_model = cnn_models[best_model_name]\n",
        "\n",
        "print(f\"Mejor modelo: {best_model_name} con accuracy: {test_accs[best_model_name]:.4f}\")\n",
        "\n",
        "# Predicciones del mejor modelo\n",
        "y_pred = best_model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\nClassification Report para {best_model_name}:\")\n",
        "print(classification_report(y_test, y_pred_classes))\n",
        "\n",
        "# Matriz de Confusi√≥n\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=range(10), yticklabels=range(10))\n",
        "plt.title(f'Matriz de Confusi√≥n - {best_model_name}', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Clase Real')\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **6. Visualizaci√≥n de Feature Maps**\n",
        "\n",
        "Vamos a ver qu√© aprenden las capas convolucionales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extraer la primera imagen de test\n",
        "test_image = x_test[0:1]  # Shape: (1, 28, 28, 1)\n",
        "test_label = y_test[0]\n",
        "\n",
        "# Crear un modelo para visualizar feature maps\n",
        "def visualize_feature_maps(model, test_image, test_label):\n",
        "    # Obtener las capas convolucionales\n",
        "    conv_layers = []\n",
        "    layer_names = []\n",
        "    \n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, (layers.Conv2D, layers.SeparableConv2D)):\n",
        "            conv_layers.append(layer.output)\n",
        "            layer_names.append(layer.name)\n",
        "    \n",
        "    # Crear modelo para extraer activaciones\n",
        "    if conv_layers:\n",
        "        activation_model = models.Model(inputs=model.input, outputs=conv_layers)\n",
        "        activations = activation_model.predict(test_image, verbose=0)\n",
        "        \n",
        "        # Visualizar los feature maps de las 3 primeras capas convolucionales\n",
        "        n_cols = min(3, len(activations))\n",
        "        fig, axes = plt.subplots(1, n_cols, figsize=(15, 5))\n",
        "        \n",
        "        if n_cols == 1:\n",
        "            axes = [axes]\n",
        "            \n",
        "        fig.suptitle(f'Feature Maps de {model.name} - D√≠gito {test_label}', \n",
        "                     fontsize=14, fontweight='bold')\n",
        "        \n",
        "        for i in range(n_cols):\n",
        "            # Obtener los primeros 8 filtros de la capa\n",
        "            activation = activations[i][0]  # Primera imagen del batch\n",
        "            n_filters = min(8, activation.shape[-1])\n",
        "            \n",
        "            # Crear subgrid para mostrar m√∫ltiples filtros\n",
        "            ax = axes[i]\n",
        "            feature_map = activation[:, :, 0]  # Primer filtro\n",
        "            \n",
        "            ax.imshow(feature_map, cmap='viridis')\n",
        "            ax.set_title(f'{layer_names[i]}\\nShape: {activation.shape}')\n",
        "            ax.axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "print(f\"\\nVisualizando feature maps del mejor modelo: {best_model_name}\")\n",
        "visualize_feature_maps(best_model, test_image, test_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **7. An√°lisis de Error y Predicciones**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lisis de errores del mejor modelo\n",
        "y_pred = best_model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Encontrar im√°genes clasificadas incorrectamente\n",
        "incorrect_indices = np.where(y_pred_classes != y_test)[0]\n",
        "\n",
        "print(f\"Im√°genes clasificadas incorrectamente: {len(incorrect_indices)} de {len(y_test)}\")\n",
        "print(f\"Accuracy: {1 - len(incorrect_indices)/len(y_test):.4f}\")\n",
        "\n",
        "# Mostrar algunos errores\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "fig.suptitle(f'Predicciones Incorrectas - {best_model_name}', \n",
        "             fontsize=14, fontweight='bold')\n",
        "\n",
        "for i in range(min(10, len(incorrect_indices))):\n",
        "    idx = incorrect_indices[i]\n",
        "    ax = axes[i//5, i%5]\n",
        "    \n",
        "    ax.imshow(x_test[idx].reshape(28, 28), cmap='gray')\n",
        "    predicted_class = y_pred_classes[idx]\n",
        "    true_class = y_test[idx]\n",
        "    confidence = np.max(y_pred[idx]) * 100\n",
        "    \n",
        "    ax.set_title(f'Real: {true_class}\\nPred: {predicted_class}\\nConf: {confidence:.1f}%',\n",
        "                color='red')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **8. Comparaci√≥n CNN vs MLPs**\n",
        "\n",
        "Comparamos nuestros modelos CNN con los MLPs de las pr√°cticas anteriores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear un MLP simple para comparar\n",
        "mlp_model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28, 1)),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "], name='MLP_Comparison')\n",
        "\n",
        "mlp_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Entrenando MLP para comparaci√≥n...\")\n",
        "mlp_history = mlp_model.fit(\n",
        "    x_train, y_train_cat,\n",
        "    validation_split=0.1,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "mlp_test_loss, mlp_test_acc = mlp_model.evaluate(x_test, y_test_cat, verbose=0)\n",
        "best_cnn_acc = max(test_accs.values())\n",
        "\n",
        "print(f\"\\nüìä CNN vs MLP COMPARISON:\")\n",
        "print(f\"-\" * 50)\n",
        "print(f\"Mejor CNN Accuracy: {best_cnn_acc:.4f} ({best_cnn_acc*100:.2f}%)\")\n",
        "print(f\"MLP Accuracy:       {mlp_test_acc:.4f} ({mlp_test_acc*100:.2f}%)\")\n",
        "print(f\"Mejora CNN:         +{(best_cnn_acc-mlp_test_acc)*100:.2f} puntos\")\n",
        "print(f\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **9. Conclusiones y An√°lisis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CONCLUSIONES DE LA PR√ÅCTICA 3 - CNNs\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"üîç AN√ÅLISIS DE ARQUITECTURAS:\")\n",
        "print(\"-\" * 40)\n",
        "print(\"‚úì CNN B√°sica: Arquitectura simple, buen rendimiento base\")\n",
        "print(\"‚úì CNN Intermedia: Mayor profundidad, regularizaci√≥n con Dropout\")\n",
        "print(\"‚úì CNN Avanzada: Batch Normalization, m√°s filtros, mejor convergencia\")\n",
        "print(\"‚úì CNN Compacta: Separable convolutions, menos par√°metros, eficiente\")\n",
        "\n",
        "print(\"üìä VENTAJAS DE LAS CNNs:\")\n",
        "print(\"-\" * 30)\n",
        "print(\"‚úì Invarianza a traslaci√≥n: filtros detectan patrones en cualquier posici√≥n\")\n",
        "print(\"‚úì Compartici√≥n de par√°metros: menos par√°metros que MLPs densas\")\n",
        "print(\"‚úì Jerarqu√≠a de features: de bordes simples a patrones complejos\")\n",
        "print(\"‚úì Pooling: reduce dimensionalidad manteniendo informaci√≥n importante\")\n",
        "\n",
        "print(\"üèóÔ∏è COMPONENTES CLAVE:\")\n",
        "print(\"-\" * 25)\n",
        "print(\"‚úì Capas Convolucionales: extracci√≥n de caracter√≠sticas locales\")\n",
        "print(\"‚úì MaxPooling: reducci√≥n de dimensionalidad e invarianza\")\n",
        "print(\"‚úì Batch Normalization: estabiliza entrenamiento, acelera convergencia\")\n",
        "print(\"‚úì Dropout: previene overfitting, mejora generalizaci√≥n\")\n",
        "print(\"‚úì GlobalAveragePooling: alternativa eficiente a Flatten + Dense\")\n",
        "\n",
        "print(\"üéØ RESULTADOS FINALES:\")\n",
        "print(\"-\" * 25)\n",
        "for name, acc in test_accs.items():\n",
        "    print(f\"‚úì {name}: {acc*100:.2f}% accuracy\")\n",
        "print(f\"‚úÖ Mejor modelo: {best_model_name} ({test_accs[best_model_name]*100:.2f}% accuracy)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **10. Experimento Adicional: CNN con Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear un modelo con data augmentation\n",
        "augmented_model = models.Sequential([\n",
        "    # Data augmentation layers\n",
        "    layers.RandomRotation(0.1, input_shape=(28, 28, 1)),\n",
        "    layers.RandomTranslation(0.1, 0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "    \n",
        "    # CNN layers\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    \n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "], name='CNN_Augmented')\n",
        "\n",
        "augmented_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Entrenando CNN con Data Augmentation...\")\n",
        "print(\"(Nota: Data augmentation se aplica solo durante entrenamiento)\")\n",
        "\n",
        "aug_history = augmented_model.fit(\n",
        "    x_train, y_train_cat,\n",
        "    validation_split=0.1,\n",
        "    epochs=8,\n",
        "    batch_size=128,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "aug_test_loss, aug_test_acc = augmented_model.evaluate(x_test, y_test_cat, verbose=0)\n",
        "\n",
        "print(f\"\\nüìä RESULTADOS CON DATA AUGMENTATION:\")\n",
        "print(f\"CNN con Augmentation: {aug_test_acc:.4f} ({aug_test_acc*100:.2f}%)\")\n",
        "print(f\"Mejora vs mejor CNN:  {(aug_test_acc-best_cnn_acc)*100:.2f} puntos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# **RESUMEN DE LA PR√ÅCTICA 3**\n",
        "\n",
        "## ‚úÖ **Objetivos Completados:**\n",
        "\n",
        "1. ‚úÖ **CNN Simple**: Implementada y probada con 2 capas convolucionales\n",
        "2. ‚úÖ **Distintas Arquitecturas**: 4 arquitecturas diferentes comparadas\n",
        "3. ‚úÖ **Comparaci√≥n de Rendimiento**: An√°lisis detallado de cada modelo\n",
        "4. ‚úÖ **Feature Maps**: Visualizaci√≥n de lo que aprenden las capas\n",
        "5. ‚úÖ **Data Augmentation**: Experimento adicional para mejorar resultados\n",
        "\n",
        "## üîç **Principales Hallazgos:**\n",
        "\n",
        "- **Batch Normalization** acelera convergencia y estabiliza entrenamiento\n",
        "- **Dropout** previene overfitting y mejora generalizaci√≥n\n",
        "- **Data Augmentation** puede mejorar robustez sin m√°s par√°metros\n",
        "- **CNNs superan a MLPs** para datos con estructura espacial como im√°genes\n",
        "- **Separable Convolutions** reducen par√°metros manteniendo rendimiento\n",
        "\n",
        "## üìä **M√©tricas Finales:**\n",
        "\n",
        "- Accuracy t√≠pica en MNIST: **98%+**\n",
        "- Reducci√≥n significativa de par√°metros vs MLPs densas\n",
        "- Mejor interpretabilidad a trav√©s de feature maps\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}