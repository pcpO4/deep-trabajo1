{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_cell"
      },
      "source": [
        "# Práctica 1: Comparativa de Optimizadores en MNIST\n",
        "\n",
        "Comparación de diferentes algoritmos de optimización en clasificación de dígitos MNIST.\n",
        "\n",
        "**Optimizadores a comparar:**\n",
        "- SGD con momentum\n",
        "- Adam\n",
        "- RMSprop\n",
        "- AdamW\n",
        "- Nadam\n",
        "- Adagrad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración inicial\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "print(\"Configuración completada\")"
      ],
      "metadata": {
        "id": "setup_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga y preparación de datos\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalización\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape para CNN\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Split validación\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    x_train, y_train, test_size=0.1, stratify=y_train, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train: {x_train.shape[0]} muestras\")\n",
        "print(f\"Validación: {x_val.shape[0]} muestras\")\n",
        "print(f\"Test: {x_test.shape[0]} muestras\")"
      ],
      "metadata": {
        "id": "data_preparation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo CNN\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        \n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        \n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        \n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Configuración de optimizadores\n",
        "optimizers_config = {\n",
        "    'SGD': tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n",
        "    'Adam': tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    'RMSprop': tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "    'AdamW': tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=1e-4),\n",
        "    'Nadam': tf.keras.optimizers.Nadam(learning_rate=0.002),\n",
        "    'Adagrad': tf.keras.optimizers.Adagrad(learning_rate=0.01)\n",
        "}\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "print(f\"Modelo CNN definido con {len(optimizers_config)} optimizadores\")\n",
        "print(f\"Épocas: {EPOCHS}, Batch size: {BATCH_SIZE}\")"
      ],
      "metadata": {
        "id": "model_definition"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento de todos los optimizadores\n",
        "results = {}\n",
        "training_histories = {}\n",
        "\n",
        "print(\"Iniciando entrenamiento comparativo...\")\n",
        "\n",
        "for opt_name, optimizer in optimizers_config.items():\n",
        "    print(f\"\\nEntrenando con {opt_name}...\")\n",
        "    \n",
        "    # Crear modelo fresco\n",
        "    model = create_model()\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    # Early stopping\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy', patience=3, restore_best_weights=True\n",
        "    )\n",
        "    \n",
        "    # Entrenar\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=(x_val, y_val),\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    # Evaluación\n",
        "    train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
        "    val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    \n",
        "    # Predicciones\n",
        "    y_pred_test = np.argmax(model.predict(x_test, verbose=0), axis=1)\n",
        "    cm_test = confusion_matrix(y_test, y_pred_test)\n",
        "    \n",
        "    # Guardar resultados\n",
        "    results[opt_name] = {\n",
        "        'model': model,\n",
        "        'training_time': training_time,\n",
        "        'train_acc': train_acc,\n",
        "        'val_acc': val_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'train_loss': train_loss,\n",
        "        'val_loss': val_loss,\n",
        "        'test_loss': test_loss,\n",
        "        'epochs_trained': len(history.history['loss']),\n",
        "        'cm_test': cm_test\n",
        "    }\n",
        "    \n",
        "    training_histories[opt_name] = history.history\n",
        "    \n",
        "    print(f\"  Tiempo: {training_time:.2f}s | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(\"\\nEntrenamiento completado\")"
      ],
      "metadata": {
        "id": "training_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tabla comparativa\n",
        "comparison_data = []\n",
        "for opt_name in optimizers_config.keys():\n",
        "    r = results[opt_name]\n",
        "    comparison_data.append({\n",
        "        'Optimizador': opt_name,\n",
        "        'Test Acc': f\"{r['test_acc']:.4f}\",\n",
        "        'Test Loss': f\"{r['test_loss']:.4f}\",\n",
        "        'Tiempo (s)': f\"{r['training_time']:.2f}\",\n",
        "        'Épocas': r['epochs_trained']\n",
        "    })\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "df_comparison = df_comparison.sort_values('Test Acc', ascending=False)\n",
        "\n",
        "print(\"Tabla comparativa:\")\n",
        "print(df_comparison.to_string(index=False))\n",
        "\n",
        "best_optimizer = df_comparison.iloc[0]['Optimizador']\n",
        "print(f\"\\nMejor optimizador: {best_optimizer}\")"
      ],
      "metadata": {
        "id": "comparison_table"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización de resultados\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Accuracy comparison\n",
        "ax = axes[0, 0]\n",
        "opt_names = list(optimizers_config.keys())\n",
        "test_accs = [results[name]['test_acc'] for name in opt_names]\n",
        "bars = ax.bar(opt_names, test_accs, alpha=0.7)\n",
        "ax.set_title('Test Accuracy por Optimizador')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_xticklabels(opt_names, rotation=45)\n",
        "for bar, acc in zip(bars, test_accs):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
        "            f'{acc:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Training time comparison\n",
        "ax = axes[0, 1]\n",
        "times = [results[name]['training_time'] for name in opt_names]\n",
        "bars = ax.bar(opt_names, times, color='coral', alpha=0.7)\n",
        "ax.set_title('Tiempo de Entrenamiento')\n",
        "ax.set_ylabel('Tiempo (s)')\n",
        "ax.set_xticklabels(opt_names, rotation=45)\n",
        "\n",
        "# Learning curves (top 3)\n",
        "ax = axes[1, 0]\n",
        "top_3 = df_comparison['Optimizador'].head(3).values\n",
        "for opt_name in top_3:\n",
        "    history = training_histories[opt_name]\n",
        "    ax.plot(history['val_accuracy'], label=f'{opt_name}', linewidth=2)\n",
        "ax.set_title('Curvas de Validación (Top 3)')\n",
        "ax.set_xlabel('Época')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Loss curves (top 3)\n",
        "ax = axes[1, 1]\n",
        "for opt_name in top_3:\n",
        "    history = training_histories[opt_name]\n",
        "    ax.plot(history['val_loss'], label=f'{opt_name}', linewidth=2)\n",
        "ax.set_title('Curvas de Loss (Top 3)')\n",
        "ax.set_xlabel('Época')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "visualization"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusión del mejor modelo\n",
        "best_model = results[best_optimizer]['model']\n",
        "cm = results[best_optimizer]['cm_test']\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=range(10), yticklabels=range(10))\n",
        "plt.title(f'Matriz de Confusión - {best_optimizer}')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Etiqueta Real')\n",
        "plt.show()\n",
        "\n",
        "# Reporte de clasificación\n",
        "y_pred_best = np.argmax(best_model.predict(x_test, verbose=0), axis=1)\n",
        "print(f\"\\nReporte de clasificación - {best_optimizer}:\")\n",
        "print(classification_report(y_test, y_pred_best, digits=4))"
      ],
      "metadata": {
        "id": "confusion_matrix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplos de predicciones\n",
        "sample_indices = np.random.choice(len(x_test), 12, replace=False)\n",
        "sample_images = x_test[sample_indices]\n",
        "sample_labels = y_test[sample_indices]\n",
        "sample_predictions = best_model.predict(sample_images, verbose=0)\n",
        "sample_pred_labels = np.argmax(sample_predictions, axis=1)\n",
        "\n",
        "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
        "fig.suptitle(f'Ejemplos de Predicciones - {best_optimizer}', fontsize=14, fontweight='bold')\n",
        "\n",
        "for i in range(12):\n",
        "    row, col = i // 4, i % 4\n",
        "    \n",
        "    axes[row, col].imshow(sample_images[i].squeeze(), cmap='gray')\n",
        "    axes[row, col].axis('off')\n",
        "    \n",
        "    color = 'green' if sample_pred_labels[i] == sample_labels[i] else 'red'\n",
        "    confidence = sample_predictions[i][sample_pred_labels[i]] * 100\n",
        "    \n",
        "    title = f\"Pred: {sample_pred_labels[i]}\\nReal: {sample_labels[i]}\\n{confidence:.1f}%\"\n",
        "    axes[row, col].set_title(title, color=color, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "prediction_examples"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}