{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pr√°ctica 1: Comparativa Avanzada de Optimizadores en MNIST\n",
        "\n",
        "**Objetivo:** Estudiar el rendimiento de diferentes algoritmos de optimizaci√≥n (optimizers) sobre el problema de clasificaci√≥n de d√≠gitos manuscritos del dataset MNIST.\n",
        "\n",
        "**Contenido:**\n",
        "1. Preparaci√≥n de datos con diferentes configuraciones\n",
        "2. Implementaci√≥n de m√∫ltiples optimizadores\n",
        "3. An√°lisis comparativo detallado\n",
        "4. Matrices de confusi√≥n\n",
        "5. Curvas de aprendizaje\n",
        "6. M√©tricas avanzadas\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Sf240kwP2c1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importaciones y Configuraci√≥n Inicial"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuraci√≥n para reproducibilidad\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configuraci√≥n de plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ Configuraci√≥n inicial completada\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preparaci√≥n Avanzada de Datos"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìã Preparaci√≥n de MNIST con Augmentaci√≥n\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Cargar y preparar MNIST\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalizar a [0,1] y expandir dimensi√≥n\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape para usar con CNN (28x28x1)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Crear split de validaci√≥n\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    x_train, y_train, test_size=0.1, stratify=y_train, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Datos de entrenamiento: {x_train.shape[0]} muestras\")\n",
        "print(f\"Datos de validaci√≥n: {x_val.shape[0]} muestras\")\n",
        "print(f\"Datos de test: {x_test.shape[0]} muestras\")\n",
        "print(f\"Clases: {len(np.unique(y_train))}\")\n",
        "\n",
        "# Data augmentation (opcional)\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.1\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Datos preparados con augmentaci√≥n configurada\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg9sEa4m2UQN",
        "outputId": "768750b7-b346-4550-e49f-b86e9448a8f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Definici√≥n de Modelo Mejorado y Configuraciones de Optimizadores"
      ],
      "metadata": {
        "id": "PgZsxj_X2tfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_improved_model(input_shape=(28, 28, 1), num_classes=10):\n",
        "    \"\"\"Modelo CNN mejorado con regularizaci√≥n\"\"\"\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        \n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        \n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        \n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Configuraci√≥n de optimizadores con hiperpar√°metros ajustados\n",
        "optimizers_config = {\n",
        "    'SGD': tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n",
        "    'Adam': tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
        "    'RMSprop': tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
        "    'AdamW': tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=1e-4),\n",
        "    'Nadam': tf.keras.optimizers.Nadam(learning_rate=0.002),\n",
        "    'Adagrad': tf.keras.optimizers.Adagrad(learning_rate=0.01)\n",
        "}\n",
        "\n",
        "# Configuraci√≥n de entrenamiento\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "print(f\"üéÜ {len(optimizers_config)} optimizadores configurados\")\n",
        "print(f\"   Modelos CNN mejorados con regularizaci√≥n\")\n",
        "print(f\"   √âpocas: {EPOCHS}, Batch size: {BATCH_SIZE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG1vAM3s2xTy",
        "outputId": "a9d2378a-47ef-45fc-bb8f-6ffca25ba2b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Entrenamiento y Evaluaci√≥n Comparativa"
      ],
      "metadata": {
        "id": "9i_221Yy3JyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "training_histories = {}\n",
        "\n",
        "print(\"üîÑ Iniciando entrenamiento comparativo...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for opt_name, optimizer in optimizers_config.items():\n",
        "    print(f\"\\n‚è±Ô∏è  Entrenando con {opt_name}...\")\n",
        "    \n",
        "    # Crear modelo fresco para cada optimizador\n",
        "    model = create_improved_model()\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    # Entrenar con early stopping\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy', patience=3, restore_best_weights=True\n",
        "    )\n",
        "    \n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=(x_val, y_val),\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    # Evaluaci√≥n\n",
        "    train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)\n",
        "    val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    \n",
        "    # Predicciones y matrices de confusi√≥n\n",
        "    y_pred_train = np.argmax(model.predict(x_train, verbose=0), axis=1)\n",
        "    y_pred_val = np.argmax(model.predict(x_val, verbose=0), axis=1)\n",
        "    y_pred_test = np.argmax(model.predict(x_test, verbose=0), axis=1)\n",
        "    \n",
        "    cm_train = confusion_matrix(y_train, y_pred_train)\n",
        "    cm_val = confusion_matrix(y_val, y_pred_val)\n",
        "    cm_test = confusion_matrix(y_test, y_pred_test)\n",
        "    \n",
        "    # Errores por clase\n",
        "    errors_per_class = {}\n",
        "    for i in range(10):\n",
        "        class_mask = (y_test == i)\n",
        "        errors_per_class[i] = 1 - (y_pred_test[class_mask] == i).mean()\n",
        "    \n",
        "    # Almacenar resultados\n",
        "    results[opt_name] = {\n",
        "        'model': model,\n",
        "        'training_time': training_time,\n",
        "        'train_acc': train_acc,\n",
        "        'val_acc': val_acc,\n",
        "        'test_acc': test_acc,\n",
        "        'train_loss': train_loss,\n",
        "        'val_loss': val_loss,\n",
        "        'test_loss': test_loss,\n",
        "        'epochs_trained': len(history.history['loss']),\n",
        "        'cm_train': cm_train,\n",
        "        'cm_val': cm_val,\n",
        "        'cm_test': cm_test,\n",
        "        'errors_per_class': errors_per_class\n",
        "    }\n",
        "    \n",
        "    training_histories[opt_name] = history.history\n",
        "    \n",
        "    print(f\"   Tiempo: {training_time:.2f}s | √âpocas: {len(history.history['loss'])} | Acc Test: {test_acc:.4f}\")\n",
        "\n",
        "print(\"\\n‚úÖ Entrenamiento completado para todos los optimizadores\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz1m6rMh3LrQ",
        "outputId": "3691d201-007c-46a6-919b-5d555186cb1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Visualizaci√≥n Comparativa Completa"
      ],
      "metadata": {
        "id": "9i_221Yy3JyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìà Generando visualizaciones comparativas...\")\n",
        "\n",
        "# Preparar datos para visualizaci√≥n\n",
        "opt_names = list(results.keys())\n",
        "\n",
        "# Gr√°ficos comparativos principales\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('An√°lisis Comparativo de Optimizadores - MNIST', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Accuracy Comparison\n",
        "ax = axes[0, 0]\n",
        "train_accs = [results[name]['train_acc'] for name in opt_names]\n",
        "val_accs = [results[name]['val_acc'] for name in opt_names]\n",
        "test_accs = [results[name]['test_acc'] for name in opt_names]\n",
        "\n",
        "x = np.arange(len(opt_names))\n",
        "width = 0.25\n",
        "\n",
        "ax.bar(x - width, train_accs, width, label='Train', alpha=0.8)\n",
        "ax.bar(x, val_accs, width, label='Validation', alpha=0.8)\n",
        "ax.bar(x + width, test_accs, width, label='Test', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Optimizador')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Accuracy por Dataset')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(opt_names, rotation=45)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim(0.95, 1.0)\n",
        "\n",
        "# 2. Training Time\n",
        "ax = axes[0, 1]\n",
        "times = [results[name]['training_time'] for name in opt_names]\n",
        "bars = ax.bar(opt_names, times, color='coral', alpha=0.8)\n",
        "ax.set_xlabel('Optimizador')\n",
        "ax.set_ylabel('Tiempo (segundos)')\n",
        "ax.set_title('Tiempo de Entrenamiento')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.setp(ax.get_xticklabels(), rotation=45)\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{times[i]:.1f}s',\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "# 3. √âpocas entrenadas (con early stopping)\n",
        "ax = axes[0, 2]\n",
        "epochs = [results[name]['epochs_trained'] for name in opt_names]\n",
        "bars = ax.bar(opt_names, epochs, color='lightgreen', alpha=0.8)\n",
        "ax.set_xlabel('Optimizador')\n",
        "ax.set_ylabel('N√∫mero de √âpocas')\n",
        "ax.set_title('√âpocas Entrenadas')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.setp(ax.get_xticklabels(), rotation=45)\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{int(epochs[i])}',\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "# 4. Curvas de aprendizaje combinadas\n",
        "ax = axes[1, 0]\n",
        "for opt_name in opt_names[:3]:  # Solo top 3 para claridad\n",
        "    history = training_histories[opt_name]\n",
        "    ax.plot(history['accuracy'], label=f'{opt_name} Train', linestyle='--', alpha=0.7)\n",
        "    ax.plot(history['val_accuracy'], label=f'{opt_name} Val', linewidth=2)\n",
        "\n",
        "ax.set_xlabel('√âpoca')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Curvas de Aprendizaje (Top 3)')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Loss comparison\n",
        "ax = axes[1, 1]\n",
        "test_losses = [results[name]['test_loss'] for name in opt_names]\n",
        "bars = ax.bar(opt_names, test_losses, color='salmon', alpha=0.8)\n",
        "ax.set_xlabel('Optimizador')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.set_title('Test Loss Comparativo')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.setp(ax.get_xticklabels(), rotation=45)\n",
        "\n",
        "# 6. Efficiency plot (Accuracy vs Time)\n",
        "ax = axes[1, 2]\n",
        "for i, opt_name in enumerate(opt_names):\n",
        "    ax.scatter(results[opt_name]['training_time'], \n",
        "               results[opt_name]['test_acc'],\n",
        "               s=150, alpha=0.7, label=opt_name)\n",
        "\n",
        "ax.set_xlabel('Tiempo de Entrenamiento (s)')\n",
        "ax.set_ylabel('Test Accuracy')\n",
        "ax.set_title('Eficiencia: Accuracy vs Tiempo')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìà Visualizaciones generadas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "sz1m6rMh3LrQ",
        "outputId": "3691d201-007c-46a6-919b-5d555186cb1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Tabla Resumen de Resultados"
      ],
      "metadata": {
        "id": "3Sw0UEJF3QsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear tabla comparativa\n",
        "comparison_data = []\n",
        "for opt_name in opt_names:\n",
        "    r = results[opt_name]\n",
        "    comparison_data.append({\n",
        "        'Optimizador': opt_name,\n",
        "        'Train Acc': f\"{r['train_acc']:.4f}\",\n",
        "        'Val Acc': f\"{r['val_acc']:.4f}\",\n",
        "        'Test Acc': f\"{r['test_acc']:.4f}\",\n",
        "        'Test Loss': f\"{r['test_loss']:.4f}\",\n",
        "        'Tiempo (s)': f\"{r['training_time']:.2f}\",\n",
        "        '√âpocas': r['epochs_trained']\n",
        "    })\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "df_comparison = df_comparison.sort_values('Test Acc', ascending=False)\n",
        "\n",
        "print(\"üìÑ Tabla Resumen de Resultados\")\n",
        "print(\"=\" * 50)\n",
        "print(df_comparison.to_string(index=False))\n",
        "\n",
        "# Identificar el mejor optimizador\n",
        "best_optimizer = df_comparison.iloc[0]['Optimizador']\n",
        "best_acc = df_comparison.iloc[0]['Test Acc']\n",
        "\n",
        "print(f\"\\nüèÜ Mejor optimizador: {best_optimizer}\")\n",
        "print(f\"   Test Accuracy: {best_acc}\")\n",
        "\n",
        "# Calcular mejora promedio\n",
        "worst_acc = float(df_comparison.iloc[-1]['Test Acc'])\n",
        "best_acc_float = float(best_acc)\n",
        "improvement = ((best_acc_float - worst_acc) / worst_acc) * 100\n",
        "\n",
        "print(f\"üìà Mejora del mejor vs peor: {improvement:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvmeAb3b3T2Y",
        "outputId": "8a6ce0be-6bac-4b2e-9c3e-ebb57800eec8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Matrices de Confusi√≥n Detalladas"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar matrices de confusi√≥n para los top 3 optimizadores\n",
        "top_3_optimizers = df_comparison['Optimizador'].head(3).values\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Matrices de Confusi√≥n - Top 3 Optimizadores (Test Set)', fontsize=14, fontweight='bold')\n",
        "\n",
        "for i, opt_name in enumerate(top_3_optimizers):\n",
        "    cm = results[opt_name]['cm_test']\n",
        "    \n",
        "    # Normalizar para mostrar porcentajes\n",
        "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
        "    \n",
        "    im = axes[i].imshow(cm_norm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    axes[i].set_title(f'{opt_name}\\nTest Acc: {results[opt_name][\"test_acc\"]:.4f}')\n",
        "    \n",
        "    # A√±adir texto en cada celda\n",
        "    thresh = cm_norm.max() / 2.\n",
        "    for j in range(cm.shape[0]):\n",
        "        for k in range(cm.shape[1]):\n",
        "            axes[i].text(k, j, f'{cm[j, k]}\\n({cm_norm[j, k]:.1f}%)',\n",
        "                        ha=\"center\", va=\"center\",\n",
        "                        color=\"white\" if cm_norm[j, k] > thresh else \"black\",\n",
        "                        fontsize=8)\n",
        "    \n",
        "    axes[i].set_ylabel('Etiqueta Real')\n",
        "    axes[i].set_xlabel('Predicci√≥n')\n",
        "    axes[i].set_xticks(np.arange(10))\n",
        "    axes[i].set_yticks(np.arange(10))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Matrices de confusi√≥n generadas\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. An√°lisis de Errores por Clase"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Error rate por clase para cada optimizador\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Crear heatmap de tasas de error\n",
        "error_matrix = np.zeros((len(opt_names), 10))\n",
        "for i, opt_name in enumerate(opt_names):\n",
        "    for digit in range(10):\n",
        "        error_matrix[i, digit] = results[opt_name]['errors_per_class'][digit] * 100\n",
        "\n",
        "sns.heatmap(error_matrix, \n",
        "            xticklabels=[f'D√≠gito {i}' for i in range(10)],\n",
        "            yticklabels=opt_names,\n",
        "            annot=True, fmt='.2f', cmap='YlOrRd',\n",
        "            cbar_kws={'label': 'Tasa de Error (%)'})\n",
        "\n",
        "plt.title('Tasa de Error por Clase y Optimizador', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Clases (D√≠gitos)')\n",
        "plt.ylabel('Optimizadores')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Identificar d√≠gitos m√°s dif√≠ciles\n",
        "avg_errors = np.mean(error_matrix, axis=0)\n",
        "difficult_digits = np.argsort(avg_errors)[::-1][:3]\n",
        "\n",
        "print(f\"\\nüî¥ D√≠gitos m√°s dif√≠ciles de clasificar:\")\n",
        "for i, digit in enumerate(difficult_digits):\n",
        "    print(f\"   {i+1}. D√≠gito {digit}: {avg_errors[digit]:.2f}% error promedio\")\n",
        "\n",
        "print(\"\\n‚úÖ An√°lisis de errores por clase completado\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Curvas de Aprendizaje Detalladas"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Curvas de aprendizaje detalladas\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, opt_name in enumerate(opt_names):\n",
        "    history = training_histories[opt_name]\n",
        "    \n",
        "    # Subplot para cada optimizador\n",
        "    ax = axes[i]\n",
        "    \n",
        "    # Accuracy curves\n",
        "    ax.plot(history['accuracy'], 'b-', label='Train Accuracy', linewidth=2)\n",
        "    ax.plot(history['val_accuracy'], 'r-', label='Val Accuracy', linewidth=2)\n",
        "    \n",
        "    # Loss curves (secondary y-axis)\n",
        "    ax2 = ax.twinx()\n",
        "    ax2.plot(history['loss'], 'b--', alpha=0.6, label='Train Loss')\n",
        "    ax2.plot(history['val_loss'], 'r--', alpha=0.6, label='Val Loss')\n",
        "    \n",
        "    ax.set_title(f'{opt_name}\\nFinal Test Acc: {results[opt_name][\"test_acc\"]:.4f}')\n",
        "    ax.set_xlabel('√âpoca')\n",
        "    ax.set_ylabel('Accuracy', color='black')\n",
        "    ax2.set_ylabel('Loss', color='gray')\n",
        "    \n",
        "    # Leyenda combinada\n",
        "    lines1, labels1 = ax.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "    ax.legend(lines1 + lines2, labels1 + labels2, loc='center right')\n",
        "    \n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Curvas de Aprendizaje Detalladas por Optimizador', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Curvas de aprendizaje detalladas generadas\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Conclusiones y Recomendaciones"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìã CONCLUSIONES DEL ESTUDIO COMPARATIVO\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "# Ranking final\n",
        "print(\"1. RANKING POR ACCURACY EN TEST:\")\n",
        "for i, row in df_comparison.iterrows():\n",
        "    print(f\"   {i+1}. {row['Optimizador']}: {row['Test Acc']} ({row['Tiempo (s)']}s)\")\n",
        "\n",
        "# Eficiencia (accuracy/time)\n",
        "print(\"\\n2. EFICIENCIA (Accuracy/Tiempo):\")\n",
        "efficiencies = {}\n",
        "for opt_name in opt_names:\n",
        "    eff = results[opt_name]['test_acc'] / results[opt_name]['training_time']\n",
        "    efficiencies[opt_name] = eff\n",
        "\n",
        "sorted_eff = sorted(efficiencies.items(), key=lambda x: x[1], reverse=True)\n",
        "for i, (opt, eff) in enumerate(sorted_eff):\n",
        "    print(f\"   {i+1}. {opt}: {eff:.6f} (acc/seg)\")\n",
        "\n",
        "print(\"\\n3. OBSERVACIONES CLAVE:\")\n",
        "print(f\"   ‚Ä¢ Mejor accuracy: {best_optimizer} ({float(best_acc):.4f})\")\n",
        "print(f\"   ‚Ä¢ M√°s eficiente: {sorted_eff[0][0]}\")\n",
        "print(f\"   ‚Ä¢ Convergencia m√°s r√°pida: {min(opt_names, key=lambda x: results[x]['epochs_trained'])}\")\n",
        "\n",
        "print(\"4. RECOMENDACIONES POR USO:\")\n",
        "print(\"   ‚úÖ Para m√°xima precisi√≥n: Adam/AdamW\")\n",
        "print(\"   ‚è±Ô∏è  Para entrenamiento r√°pido: RMSprop/Nadam\")\n",
        "print(\"   üîÑ Para uso general: Adam (mejor balance)\")\n",
        "print(\"   üìà Para problemas sparse: Adagrad\")\n",
        "\n",
        "print(\"‚úÖ PR√ÅCTICA 1 COMPLETADA Y OPTIMIZADA\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exportar Mejores Modelos"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el mejor modelo para uso en pr√°cticas posteriores\n",
        "best_model = results[best_optimizer]['model']\n",
        "\n",
        "# Evaluar modelo final\n",
        "print(f\"üéØ Modelo {best_optimizer} seleccionado como mejor\")\n",
        "print(f\"   Test Accuracy: {results[best_optimizer]['test_acc']:.4f}\")\n",
        "print(f\"   Tiempo entrenamiento: {results[best_optimizer]['training_time']:.2f}s\")\n",
        "\n",
        "# Resumen t√©cnico\n",
        "print(\"\\nüîß RESUMEN T√âCNICO:\")\n",
        "print(f\"   - Modelo: CNN con {best_model.count_params():,} par√°metros\")\n",
        "print(f\"   - Arquitectura: Conv2D + BatchNorm + Dropout\")\n",
        "print(f\"   - Regularizaci√≥n: Dropout (0.3, 0.5) + Early Stopping\")\n",
        "print(f\"   - Data Augmentation: Configurado pero no usado en este experimento\")\n",
        "print(f\"   - Optimizador ganador: {best_optimizer}\")\n",
        "\n",
        "print(\"‚úÖ Modelo listo para integraci√≥n en pr√°cticas posteriores\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}