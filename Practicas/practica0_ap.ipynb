{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title_cell"
      },
      "source": [
        "# Práctica 0: Implementación de Perceptrón Multicapa desde Cero\n\n",
        "Implementación de un perceptrón multicapa (MLP) sin usar frameworks de deep learning, solo NumPy.\n\n",
        "**Objetivos:**\n",
        "- Implementar forward pass y backpropagation manualmente\n",
        "- Probar con XOR (problema no linealmente separable)\n",
        "- Aplicar a problema de regresión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_cell"
      },
      "outputs": [],
      "source": [
        "# Configuración inicial\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n",
        "np.random.seed(42)\n",
        "plt.style.use('seaborn-v0_8')\n\n",
        "print(\"Configuración inicial completada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlp_class"
      },
      "outputs": [],
      "source": [
        "# Implementación del Perceptrón Multicapa\n",
        "class MultiLayerPerceptron:\n",
        "    def __init__(self, input_size, hidden_size, output_size, \n",
        "                 learning_rate=0.01, epochs=5000, activation='relu', task='classification'):\n",
        "        # Inicialización Xavier\n",
        "        xavier_std = np.sqrt(2.0 / (input_size + hidden_size))\n",
        "        self.W1 = np.random.normal(0, xavier_std, (input_size, hidden_size))\n",
        "        self.b1 = np.zeros((1, hidden_size))\n",
        "        \n",
        "        xavier_std2 = np.sqrt(2.0 / (hidden_size + output_size))\n",
        "        self.W2 = np.random.normal(0, xavier_std2, (hidden_size, output_size))\n",
        "        self.b2 = np.zeros((1, output_size))\n",
        "        \n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.activation = activation\n",
        "        self.task = task\n",
        "        \n",
        "        self.train_errors = []\n",
        "        self.validation_errors = []\n",
        "    \n",
        "    def _activation_function(self, x):\n",
        "        if self.activation == 'relu':\n",
        "            return np.maximum(0, x)\n",
        "        elif self.activation == 'sigmoid':\n",
        "            return 1 / (1 + np.exp(-np.clip(x, -250, 250)))\n",
        "        elif self.activation == 'tanh':\n",
        "            return np.tanh(x)\n",
        "    \n",
        "    def _activation_derivative(self, x):\n",
        "        if self.activation == 'relu':\n",
        "            return (x > 0).astype(float)\n",
        "        elif self.activation == 'sigmoid':\n",
        "            return x * (1 - x)\n",
        "        elif self.activation == 'tanh':\n",
        "            return 1 - x ** 2\n",
        "    \n",
        "    def _output_function(self, x):\n",
        "        if self.task == 'classification':\n",
        "            return 1 / (1 + np.exp(-np.clip(x, -250, 250)))\n",
        "        else:\n",
        "            return x\n",
        "    \n",
        "    def _output_derivative(self, x):\n",
        "        if self.task == 'classification':\n",
        "            return x * (1 - x)\n",
        "        else:\n",
        "            return np.ones_like(x)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        # Capa oculta\n",
        "        self.z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.a1 = self._activation_function(self.z1)\n",
        "        \n",
        "        # Capa de salida\n",
        "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
        "        self.output = self._output_function(self.z2)\n",
        "        \n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        \n",
        "        # Error capa de salida\n",
        "        error = y - self.output\n",
        "        d_output = error * self._output_derivative(self.output)\n",
        "        \n",
        "        # Error capa oculta\n",
        "        error_hidden = d_output.dot(self.W2.T)\n",
        "        d_hidden = error_hidden * self._activation_derivative(self.a1)\n",
        "        \n",
        "        # Actualizar pesos\n",
        "        self.W2 += (self.a1.T.dot(d_output) / m) * self.learning_rate\n",
        "        self.b2 += np.mean(d_output, axis=0, keepdims=True) * self.learning_rate\n",
        "        self.W1 += (X.T.dot(d_hidden) / m) * self.learning_rate\n",
        "        self.b1 += np.mean(d_hidden, axis=0, keepdims=True) * self.learning_rate\n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None, verbose=True):\n",
        "        start_time = time.time()\n",
        "        \n",
        "        for epoch in range(self.epochs):\n",
        "            self.forward(X)\n",
        "            self.backward(X, y)\n",
        "            \n",
        "            # Registrar errores\n",
        "            mse_train = np.mean((y - self.output) ** 2)\n",
        "            self.train_errors.append(mse_train)\n",
        "            \n",
        "            if X_val is not None and y_val is not None):\n",
        "                val_pred = self.forward(X_val)\n",
        "                mse_val = np.mean((y_val - val_pred) ** 2)\n",
        "                self.validation_errors.append(mse_val)\n",
        "            \n",
        "            # Mostrar progreso\n",
        "            if verbose and (epoch % (self.epochs // 10) == 0 or epoch == self.epochs - 1):\n",
        "                if X_val is not None:\n",
        "                    print(f\"Época {epoch:4d}: Train MSE = {mse_train:.6f}, Val MSE = {mse_val:.6f}\")\n",
        "                else:\n",
        "                    print(f\"Época {epoch:4d}: MSE = {mse_train:.6f}\")\n",
        "        \n",
        "        return time.time() - start_time\n",
        "    \n",
        "    def predict(self, X):\n",
        "        output = self.forward(X)\n",
        "        if self.task == 'classification':\n",
        "            return (output > 0.5).astype(int)\n",
        "        else:\n",
        "            return output\n\n",
        "print(\"Clase MultiLayerPerceptron definida\")"
      ]
    }
  ]
}