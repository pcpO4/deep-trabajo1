{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ["# Práctica 0: Implementación de Perceptrón Multicapa desde Cero\n","\n","Implementación de un perceptrón multicapa (MLP) sin usar frameworks de deep learning, solo NumPy.\n","\n","Objetivos:\n","- Implementar forward pass y backpropagation manualmente\n","- Probar con XOR (problema no linealmente separable)\n","- Aplicar a problema de regresión\n"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","\n","np.random.seed(42)\n","plt.style.use('seaborn-v0_8')\n","print('OK setup')\n"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["class MultiLayerPerceptron:\n","    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1, epochs=2000, activation='tanh', task='regression'):\n","        xavier_std = np.sqrt(2.0 / (input_size + hidden_size))\n","        self.W1 = np.random.normal(0, xavier_std, (input_size, hidden_size))\n","        self.b1 = np.zeros((1, hidden_size))\n","        xavier_std2 = np.sqrt(2.0 / (hidden_size + output_size))\n","        self.W2 = np.random.normal(0, xavier_std2, (hidden_size, output_size))\n","        self.b2 = np.zeros((1, output_size))\n","        self.learning_rate = learning_rate\n","        self.epochs = epochs\n","        self.activation = activation\n","        self.task = task\n","        self.train_errors = []\n","    def _act(self,x):\n","        if self.activation=='tanh': return np.tanh(x)\n","        if self.activation=='sigmoid': return 1/(1+np.exp(-np.clip(x,-250,250)))\n","        return np.maximum(0,x)\n","    def _act_d(self,a):\n","        if self.activation=='tanh': return 1-a*a\n","        if self.activation=='sigmoid': return a*(1-a)\n","        return (a>0).astype(float)\n","    def forward(self,X):\n","        self.z1 = X@self.W1 + self.b1\n","        self.a1 = self._act(self.z1)\n","        self.z2 = self.a1@self.W2 + self.b2\n","        self.out = self.z2 if self.task=='regression' else 1/(1+np.exp(-np.clip(self.z2,-250,250)))\n","        return self.out\n","    def backward(self,X,y):\n","        m = X.shape[0]\n","        err = y - self.out\n","        d_out = err if self.task=='regression' else err*self.out*(1-self.out)\n","        d_h = (d_out@self.W2.T)*self._act_d(self.a1)\n","        self.W2 += (self.a1.T@d_out)/m * self.learning_rate\n","        self.b2 += d_out.mean(0,keepdims=True)*self.learning_rate\n","        self.W1 += (X.T@d_h)/m * self.learning_rate\n","        self.b1 += d_h.mean(0,keepdims=True)*self.learning_rate\n","    def fit(self,X,y,verbose=False):\n","        for _ in range(self.epochs):\n","            self.forward(X); self.backward(X,y); self.train_errors.append(np.mean((y-self.out)**2))\n","    def predict(self,X):\n","        return self.forward(X)\n"]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ["# Datos de regresión simples\n","X = np.linspace(-2,2,600).reshape(-1,1)\n","y = 0.8*X[:,0]**2 + 0.6*np.sin(2*X[:,0]) + 0.2*X[:,0] + np.random.normal(0,0.15,600)\n","y = y.reshape(-1,1)\n","split=int(0.8*len(X)); Xtr,Xte=X[:split],X[split:]; ytr,yte=y[:split],y[split:]\n","# Normalización\n","Xmu,Xsd=Xtr.mean(),Xtr.std(); Ymu,Ysd=ytr.mean(),ytr.std()\n","XtrN=(Xtr-Xmu)/Xsd; XteN=(Xte-Xmu)/Xsd; ytrN=(ytr-Ymu)/Ysd\n","# Entrenar\n","mlp=MultiLayerPerceptron(1,32,1,learning_rate=0.1,epochs=2500,activation='tanh',task='regression')\n","mlp.fit(XtrN,ytrN)\n","ypN=mlp.predict(XteN); yp=ypN*Ysd+Ymu\n","print('R2:', r2_score(yte,yp))\n"]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
    "language_info": {"name": "python", "pygments_lexer": "ipython3"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}